{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/Huyen_INFO5731_Spring2020/blob/master/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9",
        "colab_type": "text"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF",
        "colab_type": "text"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k",
        "colab_type": "text"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
        "\n",
        "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
        "\n",
        "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 100 tweets by using hashtag [\"#wuhancoronovirus\"](https://twitter.com/hashtag/wuhancoronovirus) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPjGGLvpVGE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzMjKmiPTHlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question1\n",
        "\n",
        "#Yesss I fixed that problem\n",
        "\n",
        "host_url = [\"https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv\"]\n",
        "load_more_urls = [\"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7crmqm2dczaa7wxhfmzzrdtmsbzhzfmxvlnomwklyczuf43o6ss6oe2fjmzldj4k5tm5fjyr3a2pn6woclsokk47cma\", \"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cjmqqzde3yk7swhhmjqrxt4ohjjtzpwzouokkd2gbzgpnt6ucc2peyv5mbjb4dwdpdqzcxjfmg3k65z4tqdaz44w\", \"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbkqmzdizyc76wxvnzrrxs46bzhzfmxvlnomwklyczuf43o6ss6oe4vtpridv4k5vz4e43vvsqoskmtj4psbfq2qni\", \"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbpryzd6yab62tx7obtrtt4objhzfmxvlnomwklyczuf43o6ss6oe4f5nzldn4k4k7d72vy22axhza7lis2c2y7jzi\"]\n",
        "all_urls = host_url+load_more_urls\n",
        "user_names, user_links, content, date, title, review_helpfulness = [],[], [], [], [], []\n",
        "review_elements = []\n",
        "for url in all_urls:\n",
        "  request = urllib.request.urlopen (url)\n",
        "  webpage  = request.read()\n",
        "  soup = BeautifulSoup(webpage)\n",
        "\n",
        "  reviews = soup.find_all(\"div\", {\"class\":\"lister-item-content\" })\n",
        "  for review in reviews:\n",
        "    try:\n",
        "        review_title = review.find(\"a\", class_=\"title\").text.strip()\n",
        "    except:\n",
        "        review_title = \"\"\n",
        "    try:\n",
        "        review_id = review.find(\"a\")[\"href\"].split(\"/\")[2]\n",
        "    except:\n",
        "        review_id = \"\"\n",
        "    try:\n",
        "        review_date = review.find(\"span\", class_=\"review-date\").get_text()\n",
        "    except:\n",
        "        review_date = \"\"\n",
        "    try:\n",
        "        review_nickname = review.find (\"span\", class_=\"display-name-link\").get_text()\n",
        "    except:\n",
        "        review_nickname = \"\"\n",
        "    try:\n",
        "        review_content = review.find (\"div\", class_=\"text show-more__control\").get_text()\n",
        "    except:\n",
        "        review_content =\"\"\n",
        "    #print(review_content)\n",
        "    try:\n",
        "        review_rating = review. find (\"span\", class_=\"rating-other-user-rating\").getText().strip()\n",
        "        #print(review_rating)\n",
        "    except:\n",
        "        review_rating = \"\"\n",
        "    try:\n",
        "        review_helpfulness = review.find(\"div\", {\"class\": \"actions text-muted\"}).text.split(\"\\n\")[1]\n",
        "        #print(review_helpfulness)\n",
        "    except:\n",
        "        review_helpfulness = \"\"\n",
        "\n",
        "    review_elements.append([review_title, review_id, review_date, review_nickname, review_content, review_rating, review_helpfulness])\n",
        "#print(len(review_elements))\n",
        "\n",
        "df = pd.DataFrame(review_elements, columns=[\"review_title\", \"review_id\", \"review_date\", \"review_nickname\", \"review_content\", \"review_rating\", \"review_helpfulness\"])\n",
        "df\n",
        "\n",
        "with open(\"E:\\Helen\\INFO5731_Assignment2\\Joke_reviews.csv\", \"w\", newline=\"\", encoding='utf-8') as file:\n",
        "  df.to_csv(file)\n",
        "with open(\"E:\\Helen\\INFO5731_Assignment2\\Joke_reviews.csv\", \"r\", encoding='utf-8') as file:\n",
        "  pd.read_csv(file)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6v-2mpvil47",
        "colab_type": "code",
        "outputId": "1ebdf538-938f-4b05-bc95-4380ead40255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#try_codes\n",
        "load_more_data = soup.find_all(\"div\", attrs={\"class\": \"load-more-data\"}) # find this button at the end of each page\n",
        "#print(load_more_data)\n",
        "for item in load_more_data:\n",
        "  path_parse1 = \"https://www.imdb.com\"\n",
        "  path_parse2 = \"/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=\"\n",
        "  path_parse3 = item.get(\"data-key\")\n",
        "  concatenated_path = path_parse1+path_parse2+path_parse3\n",
        "  print(concatenated_path)\n",
        "#load_more_links = [\"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7crmqm2dczaa7wxhfmzzrdtmsbzhzfmxvlnomwklyczuf43o6ss6oe2fjmzldj4k5tm5fjyr3a2pn6woclsokk47cma\", \"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cjmqqzde3yk7swhhmjqrxt4ohjjtzpwzouokkd2gbzgpnt6ucc2peyv5mbjb4dwdpdqzcxjfmg3k65z4tqdaz44w\", \"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbkqmzdizyc76wxvnzrrxs46bzhzfmxvlnomwklyczuf43o6ss6oe4vtpridv4k5vz4e43vvsqoskmtj4psbfq2qni\", \"https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbpryzd6yab62tx7obtrtt4objhzfmxvlnomwklyczuf43o6ss6oe4f5nzldn4k4k7d72vy22axhza7lis2c2y7jzi\"]\n",
        "#for link in load_more_links:\n",
        " # print(link) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7crmqu2ta3qb7oux7nrvqpr42brhzfmxvlnomwklyczuf43o6ss6oe2fjmzldj4k4rmwb65sqjd2c5p4ic5kj7njmla\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBytY15j3Hkx",
        "colab_type": "code",
        "outputId": "282e83d0-3f7a-48b4-c4eb-2537e8985b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "# In this line, I am attempting to generate links with data-key in the class load-more-data. However, because, the server prohibits to get key in the second next page, so my code raise error.\n",
        "host_url = \"https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv\"\n",
        "def link_load_more (host_url):\n",
        "  request = urllib.request.urlopen (host_url)\n",
        "  webpage  = request.read()\n",
        "  soup = BeautifulSoup(webpage)\n",
        "  load_more_data = soup.find_all(\"div\", attrs={\"class\": \"load-more-data\"}) # find this button at the end of each page\n",
        "  flag = True\n",
        "  if len (load_more_data):\n",
        "  #print(load_more_data)\n",
        "    for item in load_more_data:\n",
        "      path_parse1 = \"https://www.imdb.com/\"\n",
        "      path_parse2 = \"title/tt7286456/reviews/_ajax\"\n",
        "      path_parse3 = \"?ref_=undefined&paginationKey=\"\n",
        "      try:\n",
        "        path_parse4 = item.get(\"data-key\")\n",
        "        concatenated_path = path_parse1+path_parse2+path_parse3+path_parse4\n",
        "      except KeyError:\n",
        "        flag = False\n",
        "  return concatenated_path\n",
        "\n",
        "# generate link and parse all of four pages\n",
        "\n",
        "url_nextpage1 = link_load_more(host_url)\n",
        "url_nextpage2 = link_load_more(url_nextpage1)\n",
        "url_nextpage3 = link_load_more(url_nextpage2)\n",
        "url_nextpage4 = link_load_more(url_nextpage3)\n",
        "\n",
        "print(url_nextpage1)\n",
        "print(url_nextpage2)\n",
        "print(url_nextpage3)\n",
        "print(url_nextpage4)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-79216aae5d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# generate link and parse all of four pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0murl_nextpage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_load_more\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0murl_nextpage2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_load_more\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_nextpage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0murl_nextpage3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_load_more\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_nextpage2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-79216aae5d21>\u001b[0m in \u001b[0;36mlink_load_more\u001b[0;34m(host_url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhost_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlink_load_more\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhost_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhost_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mwebpage\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwebpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'urllib' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q15UiDVAYmr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2b6d7b3a-c464-49a3-9e1a-7c16f22b4305"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "link = 'https://www.imdb.com/title/tt7286456/reviews'\n",
        "r=requests.get(link)\n",
        "r.request.headers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'User-Agent': 'python-requests/2.21.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD9-9ZQnPi2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "c9f39ad7-9e31-4686-ad2e-9251137768df"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "session = requests.Session()\n",
        "\n",
        "link = 'https://www.imdb.com/title/tt7286456/reviews'\n",
        "UA = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
        "    'Accept-Language': 'en',\n",
        "    'Accept-Encoding': 'gzip, deflate',\n",
        "    'Connection': 'close',\n",
        "    'Upgrade-Insecure-Requests': '1'\n",
        "}\n",
        "\n",
        "getlink = session.get(link, headers=UA)\n",
        "resplink = BeautifulSoup(getlink.content, 'html.parser')\n",
        "key = resplink.find('div', {'class':'load-more-data'})\n",
        "datakey = key.attrs['data-key']\n",
        "\n",
        "UAloadmore = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:73.0) Gecko/20100101 Firefox/73.0',\n",
        "    'Accept': '*/*',\n",
        "    'Accept-Language': 'en',\n",
        "    'Accept-Encoding': 'gzip, deflate',\n",
        "    'X-Requested-With': 'XMLHttpRequest',\n",
        "    'Connection': 'close',\n",
        "    'Referer': 'https://www.imdb.com/title/tt7286456/reviews'\n",
        "}\n",
        "\n",
        "a = True\n",
        "while a:\n",
        "    if key is None:\n",
        "        print('Loi')\n",
        "        a = False\n",
        "    else:\n",
        "        linkloadmore = 'https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey='+datakey\n",
        "        getloadmore = session.get(linkloadmore, headers=UAloadmore)\n",
        "        resploadmore = BeautifulSoup(getloadmore.content, 'html.parser')\n",
        "        key = resploadmore.find('div', {'class':'load-more-data'})\n",
        "        datakey = key.attrs['data-key']\n",
        "        print('https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey='+datakey)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cjmq45deyqd72xh5nrrrhrm4azhzfmxvlnomwklyczuf43o6ss6oe4f3njmdz4k4da6ioyalzd4xa252qu5ftukbqy\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbkry3dkzaf62vhtojxrxs4oab5y4hhzo5ziwr26fbyhvrl4ty4ouyflpzidvwndtuwrturx3vuipk6vekqxnoducax\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbiq45dozib7cwxfnrqrlumsbbhzfmxvlnomwklyczuf43o6ss6oizvjmbpdr4k5bqann64snddzfb2neeojfggo6i\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cboqe3t6yac7stx5obsrhrmqabyy4hhzo5ziwr26fbyhvrl4ty4ouyftmrpdjwndtvdmtgkb2h76sxkaxt4g3rbseru\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbnry5di3yh7kwxhmrrrdtmwhjjtzpwzouokkd2gbzgpnt6ucc2pa4vxnjib4d7boidprjzxgrueniiccsyawgw6\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbmqa3d4yqd7ktx3njzrts4obrhzfmxvlnomwklyczuf43o6ss6oizfzpzicv4k4situm4cwdnyvp6bafuubwci3ri\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzfqa3d63qh66vh5obvr3um2abhzfmxvlnomwklyczuf43o6ss6oe4vlnridz4k46vej4jc4olmdtctbzqkfpwpmjy\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzeq45tozyc7ctx3mbvr7unee36tbexxgvzigmk6flsfjrkqdc5ou3vtpryoblaj7bq5m2znngnpjexxabr64fq\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzlqm3da3ql7kth3njuqlum6abhzfmxvlnomwklyczuf43o6ss6oe3f7nrldv4k4zq2vdqnn6yna5xrvgxgy2hhk7q\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzlqy2dazae7guhvmrqrlsmwbjyy4hhzo5ziwr26fbyhvrl4ty4ouyfvnbjcvx5dtsap27yajsmm6qpn4lxjvxmryy4\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzkqeytcyag7sxhtnjuqpu4sbr6y4hhzo5ziwr26fbyhvrl4ty4ouzvvnrjcvx5dtx5u4xvwob72lmt5cmaucz7xnfu\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzkqi3d4yqg66xxvnzxrptmsaj6y4hhzo5ziwr26fbyhvrl4ty4ouzvznjcdzvndtsdwuvkcxwkjyyopv5mig2v3ijg\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzkq45t4zal72xxxmzrrdrmybbyy4hhzo5ziwr26fbyhvrl4ty4ouyfvmridnundtxdm3ayqktmrt3lvdyys2e6g5g6\n",
            "https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7dzkqyzdeyyk7swhfnbrrhs4ocbhzfmxvlnomwklyczuf43o6ss6oe3fvmzncr4k5oj2yqbz3rzweejd6wzyt2pkf2q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-90acecb855b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlinkloadmore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatakey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mgetloadmore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinkloadmore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mUAloadmore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mresploadmore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetloadmore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresploadmore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'load-more-data'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab_type": "code",
        "outputId": "9b2c9764-0f69-4b6d-d0b7-ccd92d2cfcc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        }
      },
      "source": [
        "# Write your code here\n",
        "#clean the text data\n",
        "from __future__ import division\n",
        "import nltk # re, pprint\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import string \n",
        "\n",
        "with open(\"E:\\Helen\\INFO5731_Assignment2\\Joke_reviews.csv\", \"r\", encoding='utf-8') as file:\n",
        "  data = pd.read_csv(file)\n",
        "\n",
        "raw_title = [str(line) for line in data.review_title]\n",
        "raw_content = [str(line) for line in data.review_content]\n",
        "# Tokenize raw text in raw_title and raw_content\n",
        "tokens_title= [nltk.word_tokenize(title) for title in raw_title]\n",
        "tokens_content = [nltk.word_tokenize(item) for item in raw_content]\n",
        "\n",
        "# PROCCESSES OF CLEANING TEXT  \n",
        "def cleaning_text (text):\n",
        "    step1 = remove_noise(text)\n",
        "    step2 = remove_num (step1)\n",
        "    step3 = remove_stop (step2)\n",
        "    step4 = lowercase (step3)\n",
        "    step5 = stemming (step4)\n",
        "    step6 = lemma (step5)\n",
        "    return step6\n",
        "\n",
        "# (1) Remove noise, such as special characters and punctuations.      \n",
        "def remove_noise (list):\n",
        "    punct=[char for char in string.punctuation]\n",
        "    noise_removed = [word for word in list if word not in punct]\n",
        "    return noise_removed\n",
        "\n",
        "#(2) Remove numbers.\n",
        "def remove_num (list):\n",
        "    num_removed  = [word for word in list if not word.isnumeric()]\n",
        "    return num_removed\n",
        "\n",
        " # (3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "def remove_stop (list):\n",
        "    stopword_removed = [word for word in list if word not in stopwords.words('english')]\n",
        "    return stopword_removed\n",
        "\n",
        "#(4) Lowercase all texts\n",
        "def lowercase (list):\n",
        "    lowercase = [word.lower() for word in list]\n",
        "    return lowercase\n",
        "# (5) Stemming\n",
        "def stemming (list):\n",
        "    ps = PorterStemmer()\n",
        "    word_stemmed = [ps.stem(word) for word in list]\n",
        "    return word_stemmed\n",
        "# (6) Lemmatization.\n",
        "def lemma (list):\n",
        "    wnl =  WordNetLemmatizer ()\n",
        "    word_lemmatized = [wnl.lemmatize(word) for word in list]\n",
        "    return word_lemmatized\n",
        "\n",
        "# Cleaning title reviews and content review\n",
        "cleaned_title = [cleaning_text (sublist) for sublist in tokens_title]\n",
        "cleaned_content = [cleaning_text (sublist) for sublist in tokens_content]\n",
        "# Save cleaned text into new columns in dataframe\n",
        "df[\"cleaned_title\"] = cleaned_title\n",
        "df[\"cleaned_content\"] = cleaned_content\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_title</th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_nickname</th>\n",
              "      <th>review_content</th>\n",
              "      <th>review_rating</th>\n",
              "      <th>review_helpfulness</th>\n",
              "      <th>cleaned_title</th>\n",
              "      <th>cleaned_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As a viewer that actually went to TIFF and wit...</td>\n",
              "      <td>rw5112402</td>\n",
              "      <td>10 September 2019</td>\n",
              "      <td>JF500</td>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6,840 out of 7,862 found t...</td>\n",
              "      <td>[a, viewer, actual, went, tiff, wit, film, n't...</td>\n",
              "      <td>[i, person, saw, hype, claim, masterpiec, over...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Outstanding movie with a haunting performance ...</td>\n",
              "      <td>rw5159304</td>\n",
              "      <td>3 October 2019</td>\n",
              "      <td>MihaVrhunc</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>3,375 out of 4,039 found t...</td>\n",
              "      <td>[outstand, movi, haunt, perform, best, charact...</td>\n",
              "      <td>[everi, movi, come, truli, make, impact, joaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Only certain people can relate</td>\n",
              "      <td>rw5168360</td>\n",
              "      <td>7 October 2019</td>\n",
              "      <td>lesterarnoldpinto</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>2,676 out of 3,304 found t...</td>\n",
              "      <td>[onli, certain, peopl, relat]</td>\n",
              "      <td>[thi, movi, felt, alon, isol, truli, relat, yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Must have put a SMILE of Satisfaction on Heath...</td>\n",
              "      <td>rw5092831</td>\n",
              "      <td>1 September 2019</td>\n",
              "      <td>Chandler_Bing_</td>\n",
              "      <td>Truly a masterpiece, The Best film of 2019, on...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>3,166 out of 3,935 found t...</td>\n",
              "      <td>[must, put, smile, satisfact, heath, ledger, '...</td>\n",
              "      <td>[truli, masterpiec, the, best, film, one, best...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Hype is real</td>\n",
              "      <td>rw5160204</td>\n",
              "      <td>4 October 2019</td>\n",
              "      <td>kdagoulis26</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>2,352 out of 2,918 found t...</td>\n",
              "      <td>[the, hype, real]</td>\n",
              "      <td>[most, time, movi, anticip, like, end, fall, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>Spare me the \"best comic book movie ever\" nons...</td>\n",
              "      <td>rw5144576</td>\n",
              "      <td>26 September 2019</td>\n",
              "      <td>gatozangado</td>\n",
              "      <td>It premiered last night in Sydney and I was lu...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>102 out of 206 found this ...</td>\n",
              "      <td>[spare, ``, best, comic, book, movi, ever, '',...</td>\n",
              "      <td>[it, premier, last, night, sydney, i, lucki, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>Don't fall for the hype</td>\n",
              "      <td>rw5206952</td>\n",
              "      <td>23 October 2019</td>\n",
              "      <td>ninjashidan</td>\n",
              "      <td>I saw the joker last night and was highly disa...</td>\n",
              "      <td>1/10</td>\n",
              "      <td>88 out of 176 found this h...</td>\n",
              "      <td>[do, n't, fall, hype]</td>\n",
              "      <td>[i, saw, joker, last, night, highli, disappoin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>As movie well overrated - acting excellent</td>\n",
              "      <td>rw5175282</td>\n",
              "      <td>9 October 2019</td>\n",
              "      <td>dhllon</td>\n",
              "      <td>The depth of the story was lacking to much foc...</td>\n",
              "      <td>2/10</td>\n",
              "      <td>59 out of 114 found this h...</td>\n",
              "      <td>[a, movi, well, overr, act, excel]</td>\n",
              "      <td>[the, depth, stori, lack, much, focu, short, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>Lives up to the hype</td>\n",
              "      <td>rw5158293</td>\n",
              "      <td>3 October 2019</td>\n",
              "      <td>i_like_jellycups</td>\n",
              "      <td>A breath of fresh airThink heath ledgers joker...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>99 out of 200 found this h...</td>\n",
              "      <td>[live, hype]</td>\n",
              "      <td>[a, breath, fresh, airthink, heath, ledger, jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Arthur Fleck: a case study of a young person's...</td>\n",
              "      <td>rw5330561</td>\n",
              "      <td>18 December 2019</td>\n",
              "      <td>Fella_shibby</td>\n",
              "      <td>This film surpassed all other films in portray...</td>\n",
              "      <td>9/10</td>\n",
              "      <td>36 out of 66 found this he...</td>\n",
              "      <td>[arthur, fleck, case, studi, young, person, 's...</td>\n",
              "      <td>[thi, film, surpass, film, portray, slow, desc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114 rows  9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          review_title  ...                                    cleaned_content\n",
              "0    As a viewer that actually went to TIFF and wit...  ...  [i, person, saw, hype, claim, masterpiec, over...\n",
              "1    Outstanding movie with a haunting performance ...  ...  [everi, movi, come, truli, make, impact, joaqu...\n",
              "2                       Only certain people can relate  ...  [thi, movi, felt, alon, isol, truli, relat, yo...\n",
              "3    Must have put a SMILE of Satisfaction on Heath...  ...  [truli, masterpiec, the, best, film, one, best...\n",
              "4                                     The Hype is real  ...  [most, time, movi, anticip, like, end, fall, s...\n",
              "..                                                 ...  ...                                                ...\n",
              "109  Spare me the \"best comic book movie ever\" nons...  ...  [it, premier, last, night, sydney, i, lucki, e...\n",
              "110                            Don't fall for the hype  ...  [i, saw, joker, last, night, highli, disappoin...\n",
              "111         As movie well overrated - acting excellent  ...  [the, depth, stori, lack, much, focu, short, a...\n",
              "112                               Lives up to the hype  ...  [a, breath, fresh, airthink, heath, ledger, jo...\n",
              "113  Arthur Fleck: a case study of a young person's...  ...  [thi, film, surpass, film, portray, slow, desc...\n",
              "\n",
              "[114 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV",
        "colab_type": "text"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "colab_type": "code",
        "outputId": "fb28254b-3ed3-45bf-ff33-1c628501c50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "# Write your code here\n",
        "#(1) Tag parts of Speech (POS) and  calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb)...\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from collections import Counter\n",
        "count_POStag = []\n",
        "for tokens in cleaned_title:\n",
        "    title_tagged = nltk.pos_tag(tokens)\n",
        "    #fd_title = nltk.FreqDist(tag for (token, tag) in title_tagged)\n",
        "    #print(fd_title)\n",
        "    count_POStag.append(Counter (tag for tokens, tag in title_tagged))\n",
        "for tokens in cleaned_content:\n",
        "    content_tagged = nltk.pos_tag(tokens)\n",
        "    #fd_title = nltk.FreqDist(tag for (token, tag) in title_tagged)\n",
        "    #print(fd_title)\n",
        "    count_POStag. append (Counter (tag for tokens, tag in content_tagged))\n",
        "    \n",
        "print(len(count_POStag))\n",
        "print(count_POStag)\n",
        "count_VB=0\n",
        "count_NN=0\n",
        "count_ADJ=0\n",
        "count_ADV=0\n",
        "for pack in count_POStag:\n",
        "  for item in pack:\n",
        "    if item ==\"VB\" or item==\"VBG\" or item==\"VBD\" or item==\"VBP\" or item==\"VBZ\":\n",
        "      count_VB+=1\n",
        "    elif item ==\"NN\" or item==\"NNS\" or item ==\"NNP\" or item==\"NNPS\":\n",
        "      count_NN+=1\n",
        "    elif item ==\"JJ\" or item ==\"JJR\" or item==\"JJS\":\n",
        "      count_ADJ+=1\n",
        "    elif item ==\"RB\" or item==\"RBR\" or item==\"RBS\":\n",
        "      count_ADV+=1\n",
        "    else:\n",
        "      pass\n",
        "print(\"The total verbs:\", count_VB)\n",
        "print(\"The total nouns:\", count_NN)\n",
        "print(\"The total adjectives:\", count_ADJ)\n",
        "print(\"The total adverbs:\", count_ADV)\n",
        "#for n in count_POStag:\n",
        " # for items in count_POStag\n",
        " # hist[key]=hist.get(valu=)+1\n",
        "  \n",
        "# (2)Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences.\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "228\n",
            "[Counter({'NN': 9, 'JJ': 3, 'DT': 1, 'VBD': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 5, 'JJS': 1, 'VB': 1, 'RB': 1, 'VBN': 1}), Counter({'NN': 3, 'JJ': 1}), Counter({'NN': 4, 'RB': 2, 'MD': 1, 'VB': 1, 'JJ': 1, 'POS': 1}), Counter({'DT': 1, 'NN': 1, 'JJ': 1}), Counter({'NN': 2}), Counter({'RB': 1, 'VB': 1, 'WRB': 1, 'JJ': 1, 'VBP': 1}), Counter({'NN': 2, 'VBD': 1, 'JJ': 1}), Counter({'NN': 3, 'DT': 1, 'RB': 1, 'VBD': 1}), Counter({'NN': 6, 'POS': 1, 'JJS': 1, 'VBZ': 1, ':': 1, 'VBD': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'JJ': 2, 'NN': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 4, 'RB': 2, 'VB': 1}), Counter({'NN': 2}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 2}), Counter({'NN': 2}), Counter({'VB': 2, 'VBP': 1, 'RB': 1}), Counter({'NN': 2, 'MD': 1, 'VB': 1}), Counter({'NN': 3, 'CD': 1, 'JJS': 1, 'VBP': 1, 'RB': 1, 'VBN': 1}), Counter({'IN': 1}), Counter({'NN': 2}), Counter({'IN': 1, 'DT': 1, 'NN': 1}), Counter({'NN': 1}), Counter({'NN': 1}), Counter({'NN': 2, 'DT': 1}), Counter({'JJ': 2, 'VBZ': 1, 'RB': 1, 'VB': 1}), Counter({'``': 1, 'DT': 1, 'VBZ': 1, 'NN': 1, \"''\": 1}), Counter({'NN': 2}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 3, 'CC': 1, 'JJS': 1, 'VBP': 1, 'RB': 1, 'VBN': 1}), Counter({'NN': 2}), Counter({'RB': 2, 'NN': 2, 'JJ': 1, 'POS': 1, '``': 1, 'JJS': 1, \"''\": 1}), Counter({'JJ': 3, 'VBP': 2, 'NN': 2, 'IN': 1}), Counter({'NN': 3, 'JJ': 1, 'IN': 1}), Counter({'NN': 5, 'JJ': 2, 'VB': 1, 'CD': 1, 'JJS': 1, 'NNS': 1, 'VBP': 1}), Counter({'NN': 3, 'VBP': 2, 'VBD': 1, 'RB': 1, 'JJ': 1}), Counter({'JJ': 4, 'NN': 4, 'VBP': 3, 'VBN': 2, 'RB': 2, 'NNS': 1, 'IN': 1, 'PRP': 1}), Counter({'NN': 3, 'JJ': 1, '``': 1, \"''\": 1}), Counter({'NN': 3, 'JJ': 1, 'DT': 1}), Counter({'NN': 1}), Counter({'NN': 5, 'VBP': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 3, 'JJ': 1, 'VBP': 1, 'IN': 1}), Counter({'NNS': 1, 'NN': 1}), Counter({'JJ': 3, 'NN': 2}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 5, 'VBD': 1}), Counter({'NN': 2, 'VBZ': 1, 'WRB': 1, 'DT': 1, 'JJ': 1, 'MD': 1, 'VB': 1}), Counter({'NN': 4, 'VBD': 2, 'JJS': 1, 'DT': 1}), Counter({'NN': 2, 'VB': 1}), Counter({'WP': 1, 'VBZ': 1, 'JJ': 1, 'NN': 1}), Counter({'NN': 2}), Counter({'NN': 4, 'RB': 2, 'JJ': 2, 'NNS': 1, 'VBP': 1}), Counter({'NN': 1, 'POS': 1, 'PRP': 1}), Counter({'NN': 2}), Counter({'NN': 2, 'VB': 2, 'RB': 1, 'JJ': 1, 'VBP': 1}), Counter({'RB': 2, ':': 1}), Counter({'NN': 2, 'JJS': 1, 'IN': 1, 'DT': 1}), Counter({'RB': 1, 'JJ': 1}), Counter({'VBP': 1, 'RB': 1, 'VB': 1, 'NN': 1}), Counter({'NN': 4, 'JJ': 2}), Counter({'NN': 2, 'RB': 1}), Counter({'NN': 4, 'VBD': 1, 'IN': 1}), Counter({'NN': 1}), Counter({'NN': 1}), Counter({'NN': 3, 'JJ': 1}), Counter({'NN': 4, 'DT': 1, 'JJS': 1, 'VBN': 1, 'VBD': 1}), Counter({'NN': 1, 'VBP': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 2}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 1}), Counter({'RB': 1, 'NN': 1}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 2}), Counter({'NN': 2}), Counter({'NN': 6, 'IN': 1, 'JJS': 1}), Counter({'VBP': 1, 'JJ': 1, 'CD': 1, 'RB': 1, 'IN': 1, 'VB': 1}), Counter({'NNS': 1, 'NN': 1}), Counter({'NN': 2}), Counter({'NN': 2, 'DT': 1}), Counter({'NN': 1}), Counter({'NN': 3}), Counter({'NN': 2}), Counter({'JJ': 2, 'NN': 2, 'DT': 1}), Counter({'NN': 4, 'JJ': 1, ':': 1}), Counter({'NN': 2}), Counter({'NN': 5, 'IN': 1, 'RB': 1, 'JJS': 1, 'JJ': 1}), Counter({'NN': 4, 'RB': 1, 'VBD': 1, 'CD': 1}), Counter({'NNS': 1, 'VBP': 1}), Counter({'CD': 1, 'DT': 1, 'JJS': 1, 'NN': 1, 'RB': 1}), Counter({'NN': 4, 'JJ': 2}), Counter({'IN': 2, 'NN': 2}), Counter({'NN': 1}), Counter({'NN': 2, ':': 1}), Counter({'NN': 1}), Counter({'NN': 1, 'VBD': 1}), Counter({'NN': 2}), Counter({'NN': 9, 'VBP': 1, 'JJ': 1}), Counter({'NN': 3, 'VBP': 1, 'RB': 1}), Counter({'NN': 4, 'POS': 1}), Counter({'NN': 1}), Counter({'NN': 2, 'DT': 1}), Counter({'NN': 3, 'VBD': 1, 'JJ': 1}), Counter({'RB': 1, 'JJ': 1, 'NN': 1}), Counter({'NN': 2, 'RB': 1}), Counter({'JJ': 2, 'NN': 2, '``': 1, 'JJS': 1, 'RB': 1, \"''\": 1, 'NNS': 1}), Counter({'VBP': 1, 'RB': 1, 'VB': 1, 'NN': 1}), Counter({'NN': 3, 'DT': 1, 'RB': 1, 'IN': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 8, 'JJ': 2, 'RB': 1, 'POS': 1}), Counter({'NN': 57, 'JJ': 19, 'VBP': 7, 'RB': 6, 'VB': 3, 'NNS': 3, 'VBN': 3, 'POS': 3, 'VBD': 2, 'DT': 2, 'IN': 2, 'JJS': 2, 'MD': 2, 'VBZ': 1, 'WRB': 1}), Counter({'NN': 26, 'JJ': 10, 'RB': 4, 'VBP': 3, 'POS': 3, 'NNS': 1, ':': 1, 'MD': 1, 'VB': 1, 'VBD': 1, 'JJS': 1, 'VBN': 1}), Counter({'NN': 18, 'JJ': 9, 'VBP': 5, 'NNS': 2, 'VBD': 1, 'PRP': 1, 'DT': 1, 'CC': 1, 'CD': 1, 'RBR': 1, 'IN': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 20, 'JJ': 8, 'JJS': 3, 'VB': 2, 'VBP': 2, 'VBZ': 1, 'DT': 1, 'CD': 1, ':': 1, 'CC': 1, 'VBG': 1, 'RB': 1}), Counter({'NN': 26, 'JJ': 10, 'VBP': 4, 'JJS': 2, 'NNS': 2, 'IN': 2, '``': 2, \"''\": 2, 'RB': 2, 'PRP': 1, 'VBN': 1, 'JJR': 1, 'VBZ': 1, 'DT': 1}), Counter({'NN': 27, 'JJ': 9, 'IN': 4, 'POS': 4, 'DT': 3, 'VBD': 3, 'VB': 2, 'VBP': 2, 'FW': 1, 'PRP': 1, 'VBZ': 1}), Counter({'NN': 27, 'JJ': 19, 'VBP': 8, 'RB': 8, 'VB': 7, 'CC': 4, 'DT': 3, 'VBD': 3, 'RBS': 2, 'NNS': 1, 'MD': 1, 'VBN': 1, 'VBZ': 1, 'IN': 1, 'PRP': 1, 'VBG': 1, 'JJS': 1}), Counter({'NN': 19, 'VB': 4, 'VBP': 3, 'JJ': 3, 'PRP': 1, 'VBZ': 1, 'FW': 1, 'MD': 1, 'POS': 1, 'CC': 1, 'RB': 1, 'DT': 1, 'IN': 1}), Counter({'NN': 77, 'JJ': 37, 'RB': 7, 'POS': 6, 'VBP': 5, 'VB': 4, 'IN': 3, 'PRP': 3, 'MD': 3, 'JJS': 3, 'VBN': 2, 'VBZ': 2, 'CC': 1, 'VBD': 1, 'DT': 1, 'NNS': 1, 'CD': 1, 'WP': 1}), Counter({'NN': 29, 'JJ': 14, 'VB': 6, 'VBZ': 3, 'VBP': 2, 'VBD': 2, 'RB': 2, 'PRP': 1, 'POS': 1, 'CC': 1, 'NNP': 1, 'TO': 1, 'RP': 1, 'JJS': 1}), Counter({'NN': 20, 'JJ': 13, 'RB': 9, 'VB': 7, 'VBP': 5, 'MD': 2, 'NNS': 1, 'VBD': 1, 'CD': 1, '``': 1, \"''\": 1}), Counter({'NN': 31, 'JJ': 14, 'VBP': 6, 'VBD': 5, 'RB': 5, 'NNS': 3, 'VB': 3, 'PRP': 2, 'IN': 2, 'DT': 1, '``': 1, \"''\": 1, 'VBZ': 1, 'MD': 1, 'JJS': 1}), Counter({'NN': 10, 'JJ': 2, 'VBP': 2, 'DT': 1, 'NNS': 1}), Counter({'NN': 4, 'JJ': 3, 'DT': 1, 'VBP': 1, 'RB': 1}), Counter({'NN': 7, 'JJ': 2, 'VBP': 1}), Counter({'NN': 65, 'JJ': 32, 'VBD': 9, 'VB': 6, 'VBP': 5, 'IN': 3, 'RB': 3, 'MD': 3, 'DT': 2, ':': 1, 'WDT': 1, 'WP': 1, 'TO': 1, 'NNS': 1, 'CC': 1}), Counter({'NN': 34, 'JJ': 10, 'VBP': 4, 'NNS': 2, 'RB': 2, 'POS': 2, 'VB': 1, 'PRP': 1, 'IN': 1}), Counter({'NN': 38, 'JJ': 18, 'VB': 4, 'RB': 4, 'VBP': 4, 'VBD': 3, 'CC': 2, 'IN': 2, 'NNS': 1, 'MD': 1, 'DT': 1, 'RBR': 1}), Counter({'NN': 89, 'JJ': 39, 'VBP': 12, 'VB': 10, 'RB': 8, 'POS': 7, 'NNS': 4, 'VBZ': 3, 'IN': 3, 'CD': 3, 'MD': 2, 'JJS': 2, 'VBD': 2, 'PRP': 1, 'VBN': 1, 'VBG': 1}), Counter({'NN': 81, 'JJ': 36, 'RB': 16, 'VBD': 14, 'VB': 12, 'VBP': 9, 'VBN': 4, 'MD': 4, 'POS': 4, 'PRP': 4, 'VBZ': 4, 'DT': 3, 'IN': 3, 'CD': 2, ':': 1, 'EX': 1, 'WP': 1, 'NNS': 1, 'CC': 1}), Counter({'NN': 40, 'JJ': 15, 'VBP': 7, 'VBN': 4, 'VBD': 3, 'IN': 3, 'DT': 3, 'VBZ': 2, 'NNS': 2, 'POS': 2, 'RB': 2, 'FW': 1, 'JJS': 1, 'VB': 1, 'CD': 1, 'RBR': 1, 'PRP': 1, 'MD': 1}), Counter({'NN': 32, 'JJ': 8, 'VBP': 6, 'IN': 5, 'VB': 4, 'RB': 3, 'CD': 3, 'VBD': 2, 'DT': 1, 'MD': 1, 'POS': 1}), Counter({'NN': 27, 'JJ': 11, 'VBP': 8, ':': 3, 'IN': 3, 'VBD': 2, 'VBN': 2, 'CC': 1, 'JJS': 1, 'POS': 1, 'RBR': 1, 'RB': 1, 'MD': 1, 'VB': 1}), Counter({'NN': 33, 'VBP': 5, 'JJ': 5, 'VB': 4, 'RB': 4, 'NNS': 4, 'VBD': 4, 'CD': 3, 'PRP$': 1, 'TO': 1, 'JJS': 1, 'DT': 1, 'PRP': 1}), Counter({'NN': 32, 'JJ': 13, 'DT': 5, 'VB': 3, 'VBP': 3, 'NNS': 2, 'RB': 2, 'VBD': 2, 'IN': 2, 'MD': 2, 'POS': 1}), Counter({'NN': 32, 'JJ': 13, 'DT': 5, 'VB': 3, 'VBP': 3, 'NNS': 2, 'RB': 2, 'VBD': 2, 'IN': 2, 'MD': 2, 'POS': 1}), Counter({'NN': 52, 'JJ': 21, 'VBP': 15, 'VB': 8, 'IN': 5, 'PRP': 4, 'RB': 4, 'VBZ': 3, 'POS': 2, 'DT': 2, 'NNS': 2, 'VBN': 2, 'JJR': 2, 'MD': 2, 'VBD': 1, 'JJS': 1, 'EX': 1, 'WDT': 1, '``': 1, \"''\": 1, 'CD': 1}), Counter({'NN': 30, 'JJ': 17, 'VBD': 5, 'RB': 5, 'VBP': 4, 'DT': 4, 'NNS': 3, 'POS': 3, 'IN': 3, 'WRB': 2, 'VB': 1, 'VBZ': 1, 'PRP': 1}), Counter({'NN': 135, 'JJ': 47, 'IN': 11, 'RB': 10, 'VBP': 10, 'DT': 9, 'VB': 8, 'VBD': 8, 'MD': 5, 'VBZ': 3, 'JJR': 2, 'PRP': 2, 'VBG': 2, 'POS': 2, 'RBR': 2, 'NNS': 1, 'FW': 1, ':': 1, 'CD': 1, 'WP$': 1}), Counter({'NN': 27, 'JJ': 8, 'RB': 8, 'IN': 5, 'VB': 5, 'VBP': 4, 'NNS': 2, 'DT': 2, 'MD': 2, '``': 1, \"''\": 1, 'VBN': 1, 'FW': 1, 'POS': 1, 'VBD': 1, 'CC': 1, 'RBR': 1, 'VBZ': 1}), Counter({'NN': 30, 'DT': 5, 'JJ': 4, \"''\": 1, 'CD': 1, 'VBG': 1, 'PRP': 1, 'VBP': 1}), Counter({'NN': 27, 'JJ': 10, 'VBD': 6, 'DT': 2, 'VBP': 2, 'RB': 2, 'IN': 1, 'FW': 1, 'CC': 1, 'CD': 1, 'PRP$': 1, 'JJS': 1}), Counter({'NN': 15, 'VBP': 4, 'JJ': 4, 'IN': 3, 'VB': 2, 'DT': 1, 'PRP': 1, 'NNS': 1, 'RB': 1, '``': 1, \"''\": 1, 'VBZ': 1, 'JJR': 1, 'POS': 1}), Counter({'NN': 116, 'JJ': 58, 'VBP': 27, 'RB': 19, 'IN': 16, 'VB': 14, '``': 7, 'VBD': 6, 'NNS': 6, 'MD': 4, 'VBN': 4, \"''\": 3, 'POS': 3, 'VBZ': 3, 'RP': 2, 'DT': 1, 'CD': 1, 'JJR': 1, 'PRP$': 1, 'RBR': 1, 'JJS': 1, 'PRP': 1}), Counter({'NN': 57, 'JJ': 29, 'VBP': 13, 'RB': 6, 'VBN': 5, 'VB': 3, 'VBD': 3, 'IN': 3, 'MD': 2, 'JJR': 2, 'CC': 1, 'DT': 1, 'JJS': 1, ':': 1, 'PRP': 1, 'NNS': 1}), Counter({'NN': 60, 'JJ': 17, 'DT': 7, 'VB': 7, 'CD': 6, 'RB': 4, 'VBP': 4, 'POS': 3, 'JJS': 3, 'IN': 3, 'MD': 3, 'JJR': 3, 'VBD': 2, 'VBN': 1, 'VBZ': 1, 'NNP': 1, 'NNS': 1, 'RP': 1}), Counter({'NN': 198, 'JJ': 74, 'VBP': 24, 'RB': 22, 'VB': 19, 'IN': 12, 'POS': 10, 'VBD': 7, '``': 6, \"''\": 6, 'CD': 5, 'DT': 5, 'CC': 5, 'VBN': 4, 'MD': 4, 'JJS': 2, 'VBG': 2, 'NNS': 2, 'FW': 2, 'TO': 2, 'VBZ': 1, 'NNP': 1, 'PRP': 1, ':': 1}), Counter({'NN': 10, 'JJS': 4, 'JJ': 3, 'VBP': 3, 'RB': 2, 'VB': 2, 'NNS': 1, 'JJR': 1, 'IN': 1, 'CD': 1}), Counter({'NN': 68, 'JJ': 24, 'VBP': 11, 'RB': 8, 'IN': 5, 'POS': 5, 'VB': 5, 'MD': 3, 'VBN': 2, 'NNS': 2, 'WP$': 1, 'RBR': 1, 'VBZ': 1}), Counter({'NN': 44, 'JJ': 20, 'VB': 10, 'VBP': 6, 'MD': 5, 'NNS': 3, 'RB': 3, 'IN': 3, 'CD': 3, 'PRP': 2, 'VBD': 1, 'CC': 1, 'DT': 1, '``': 1, \"''\": 1, 'POS': 1, 'FW': 1, 'EX': 1, 'VBG': 1}), Counter({'NN': 80, 'JJ': 28, 'VBP': 10, 'VB': 7, 'RB': 6, 'NNS': 4, 'IN': 4, '``': 3, 'CD': 3, 'POS': 3, 'MD': 3, 'CC': 2, 'VBZ': 2, 'VBD': 2, \"''\": 1, 'JJR': 1, 'DT': 1, 'VBN': 1, 'PRP': 1, 'JJS': 1, ':': 1, 'WP': 1, 'EX': 1}), Counter({'NN': 9, 'CD': 2, 'JJS': 2, 'VBZ': 1, 'VBP': 1, 'RB': 1}), Counter({'NN': 97, 'JJ': 36, 'RB': 16, 'VBP': 14, 'IN': 11, 'VB': 10, 'VBD': 7, 'PRP': 6, 'DT': 5, 'MD': 4, 'VBN': 4, 'CC': 3, 'CD': 3, 'RP': 3, 'VBZ': 2, 'JJS': 2, 'POS': 2, 'JJR': 1, 'RBR': 1, 'NNS': 1}), Counter({'NN': 21, 'JJ': 6, 'VB': 3, 'POS': 2, 'IN': 2, 'VBP': 2, 'VBD': 1, 'MD': 1, 'NNS': 1}), Counter({'NN': 12, 'JJ': 5, 'RB': 5, 'VBP': 4, 'VBD': 2, 'VB': 2, 'IN': 2, 'NNS': 1, 'DT': 1, 'VBN': 1, ':': 1}), Counter({'NN': 78, 'JJ': 25, 'RB': 7, 'VB': 7, 'VBP': 7, 'VBD': 5, 'IN': 3, 'PRP': 2, 'VBZ': 2, 'MD': 2, 'DT': 2, 'VBN': 2, 'FW': 1, 'JJR': 1}), Counter({'NN': 17, 'JJ': 10, 'VBP': 2, 'VBD': 2, 'RB': 2, 'VBZ': 2, 'POS': 1, 'IN': 1, 'NNS': 1, 'DT': 1, 'NNP': 1, 'RBR': 1, ':': 1, 'PRP': 1, 'VB': 1}), Counter({'NN': 23, 'JJ': 6, 'VBD': 4, 'RB': 3, 'IN': 3, 'WP': 1, 'VB': 1, 'FW': 1, 'CC': 1}), Counter({'NN': 16, 'JJ': 9, 'VB': 5, 'VBP': 3, 'RB': 3, 'VBD': 2, 'IN': 2, 'NNS': 1, 'MD': 1, 'CD': 1}), Counter({'NN': 17, 'JJ': 6, 'VBP': 4, 'VBD': 3, 'CD': 3, 'VB': 3, 'PRP': 2, 'RP': 1, 'JJS': 1, 'VBN': 1, 'RB': 1, 'CC': 1}), Counter({'NN': 177, 'JJ': 78, 'VB': 31, 'VBP': 26, 'RB': 22, 'MD': 16, 'IN': 15, 'PRP': 13, 'VBD': 11, 'CC': 9, 'POS': 9, 'CD': 6, 'VBZ': 5, 'DT': 5, 'NNS': 4, 'JJR': 2, 'RBR': 1, 'EX': 1, 'WDT': 1, 'VBN': 1, 'FW': 1}), Counter({'NN': 19, 'JJ': 7, ':': 3, 'DT': 2, 'VBP': 2, 'POS': 1, 'CC': 1, 'IN': 1, 'VB': 1, 'JJS': 1, 'WP': 1}), Counter({'NN': 19, 'JJ': 13, 'RB': 4, 'VBD': 3, 'VBP': 2, 'VB': 2, 'NNS': 1, 'PRP': 1, 'CC': 1, 'VBN': 1}), Counter({'NN': 10, 'JJ': 5, 'RB': 2, 'VBP': 2, 'VBD': 1}), Counter({'NN': 33, 'JJ': 16, 'RB': 6, 'VB': 6, 'VBP': 4, 'IN': 4, 'NNS': 3, 'VBD': 3, 'POS': 2, '``': 2, \"''\": 2, 'CD': 2, 'DT': 2, 'MD': 2, 'FW': 1, 'WP$': 1, 'VBZ': 1}), Counter({'NN': 139, 'JJ': 42, 'VBP': 19, 'RB': 17, 'VB': 12, 'VBD': 10, 'IN': 9, 'CD': 8, 'POS': 5, 'VBZ': 5, 'MD': 4, 'PRP': 3, 'VBN': 3, 'RBR': 2, 'NNS': 2, 'DT': 2, 'FW': 1, 'JJR': 1, 'EX': 1, 'RBS': 1, 'JJS': 1, 'PDT': 1, 'NNP': 1}), Counter({'NN': 26, 'VBP': 6, 'JJ': 5, 'VB': 2, 'POS': 2, 'VBZ': 1, 'RB': 1}), Counter({'NN': 25, 'JJ': 11, 'VBP': 5, 'RB': 4, 'IN': 3, 'VBD': 3, 'CD': 2, 'VB': 2, 'POS': 1, 'VBN': 1, 'NNS': 1, 'MD': 1}), Counter({'NN': 21, 'JJ': 10, 'VB': 5, 'POS': 5, 'VBP': 3, 'PRP': 2, 'VBZ': 2, 'RB': 2, 'IN': 2, 'CD': 1, 'VBD': 1, 'JJR': 1, 'WRB': 1, 'CC': 1}), Counter({'NN': 11, 'VBP': 2, 'JJ': 2, 'DT': 1, 'POS': 1, 'VBN': 1}), Counter({'NN': 14, 'RB': 4, 'VB': 4, 'VBP': 3, 'JJ': 3, ':': 2, 'VBD': 2, 'JJS': 1, 'VBN': 1, 'MD': 1, 'IN': 1, 'CC': 1, 'CD': 1}), Counter({'NN': 16, 'JJ': 5, 'IN': 3, 'VBP': 2, 'VB': 2, 'PRP': 1, 'VBZ': 1, 'CC': 1, 'RB': 1, 'POS': 1, 'VBN': 1, 'TO': 1}), Counter({'NN': 126, 'JJ': 59, 'RB': 30, 'VBP': 20, 'VB': 16, 'IN': 15, 'POS': 11, 'VBD': 10, 'VBZ': 7, 'PRP': 6, 'CD': 6, 'DT': 4, 'NNS': 4, 'MD': 3, 'JJR': 2, 'JJS': 2, 'FW': 1, 'CC': 1, 'VBN': 1, 'TO': 1, 'WP': 1, '``': 1, \"''\": 1}), Counter({'NN': 1}), Counter({'NN': 44, 'JJ': 16, 'VBP': 13, 'RB': 6, 'VB': 3, 'DT': 3, 'IN': 3, 'VBN': 2, 'VBD': 2, 'VBZ': 2, 'PRP': 1, 'NNS': 1, 'POS': 1, 'EX': 1, 'RBR': 1}), Counter({'NN': 9, 'JJ': 5, 'VBD': 3, 'MD': 2, 'VB': 2, ':': 2, 'VBN': 2, 'DT': 1, 'PRP': 1, 'RB': 1, 'VBP': 1}), Counter({'NN': 41, 'JJ': 7, 'IN': 5, 'VBP': 3, 'RB': 2, 'POS': 2, 'CC': 2, 'VBD': 2, 'VBN': 2, 'JJS': 1, 'PRP': 1, 'VBZ': 1, 'DT': 1, 'NNS': 1, 'TO': 1, 'VB': 1, 'WRB': 1, 'RBR': 1}), Counter({'NN': 13, 'JJ': 5, 'IN': 4, 'RB': 2, 'DT': 2, 'VBP': 1, 'VBN': 1, 'FW': 1, 'VB': 1, 'VBZ': 1}), Counter({'NN': 18, 'JJ': 5, 'VBP': 3, 'RB': 2, 'VB': 2, 'IN': 1, 'PRP': 1, 'VBZ': 1, 'NNS': 1, 'DT': 1, 'VBN': 1, 'CD': 1}), Counter({'NN': 94, 'JJ': 30, 'VBP': 15, 'RB': 14, 'IN': 9, 'DT': 7, 'VBD': 6, 'NNS': 6, 'VBZ': 5, 'POS': 4, 'VB': 4, 'FW': 3, 'PRP': 2, 'EX': 1, 'JJR': 1, 'CC': 1}), Counter({'NN': 18, 'JJ': 7, 'VB': 4, 'RB': 2, 'CC': 2, 'PRP': 2, 'POS': 2, 'VBD': 1, 'VBP': 1, 'DT': 1, 'VBZ': 1, 'IN': 1, 'WP': 1}), Counter({'NN': 37, 'JJ': 22, 'VBP': 6, 'IN': 5, 'VB': 4, 'DT': 3, 'CD': 3, 'NNS': 2, 'VBN': 2, 'POS': 2, 'CC': 2, 'RB': 2, 'MD': 1, 'JJS': 1}), Counter({'NN': 8, 'JJS': 2, 'CD': 1, 'VBN': 1, 'POS': 1, 'JJ': 1}), Counter({'NN': 96, 'JJ': 35, 'VBP': 10, 'VB': 8, 'RB': 7, 'IN': 6, 'VBZ': 4, 'VBD': 4, 'PRP': 4, 'MD': 4, 'NNS': 4, ':': 2, 'POS': 2, 'JJS': 2, 'VBN': 2, 'WDT': 2, 'RBR': 1, 'JJR': 1, 'DT': 1, 'CC': 1, '``': 1, \"''\": 1, 'CD': 1}), Counter({'NN': 26, 'JJ': 5, 'VBP': 3, 'VBD': 3, 'IN': 3, 'VB': 2, 'DT': 2, 'CD': 1, 'NNS': 1, 'VBN': 1, 'PRP': 1, 'RB': 1, 'NNP': 1}), Counter({'NN': 29, 'JJ': 4, 'VBP': 4, 'VBD': 3, 'IN': 2, 'RB': 2, 'PRP': 1, 'VBZ': 1, 'VBN': 1, 'NNS': 1, 'MD': 1, 'VB': 1, 'DT': 1, 'POS': 1}), Counter({'NN': 13, 'DT': 2, 'VBZ': 2, 'JJ': 2, 'RB': 1, 'VBN': 1, 'VBD': 1, 'RBR': 1, 'IN': 1}), Counter({'NN': 4, 'JJS': 1, 'JJ': 1, 'VBP': 1}), Counter({'NN': 21, 'JJ': 4, 'RBR': 2, 'DT': 1, 'TO': 1, 'VB': 1, '``': 1, 'CD': 1, 'JJS': 1, \"''\": 1}), Counter({'NN': 82, 'JJ': 36, 'VBP': 11, 'RB': 8, 'VBD': 7, 'IN': 6, 'POS': 5, 'VBN': 3, 'DT': 3, 'VB': 3, 'CD': 2, 'JJS': 2, 'MD': 2, 'NNS': 2, 'PRP': 1, 'CC': 1}), Counter({'NN': 14, 'JJ': 3, 'POS': 1, ':': 1, 'VBD': 1, 'RB': 1, 'VBN': 1, 'VBZ': 1, 'DT': 1, 'VB': 1, 'IN': 1}), Counter({'NN': 27, 'JJ': 6, 'VBP': 3, 'NNS': 2, 'VBD': 2, 'VBN': 1, 'PRP': 1, 'RB': 1, 'VB': 1, 'IN': 1}), Counter({'NN': 28, 'JJ': 7, '``': 5, \"''\": 5, 'RB': 2, 'IN': 2, 'RBR': 2, 'VBP': 1, 'VB': 1, 'VBD': 1, 'VBN': 1}), Counter({'NN': 14, 'JJ': 3, 'WP': 1, 'VBZ': 1, 'VBP': 1, 'VB': 1, 'PRP': 1, 'VBD': 1, 'RB': 1, 'VBN': 1, 'IN': 1, 'DT': 1}), Counter({'NN': 7, 'VBP': 5, 'RB': 2, 'JJ': 2, 'NNS': 1, 'DT': 1}), Counter({'NN': 40, 'JJ': 29, 'VB': 7, 'MD': 6, 'RB': 6, 'VBP': 5, 'DT': 3, 'IN': 3, 'POS': 3, 'VBZ': 2, 'VBN': 2, 'WP': 1, 'WDT': 1, 'JJR': 1, 'CD': 1, 'NNS': 1}), Counter({'NN': 14, 'FW': 1, '$': 1, 'CD': 1, 'JJ': 1, 'VBZ': 1, 'JJR': 1}), Counter({'NN': 111, 'JJ': 31, 'RB': 19, 'VBP': 19, 'IN': 14, 'VB': 12, 'MD': 6, 'VBD': 5, 'CC': 5, 'VBN': 4, 'PRP': 4, 'DT': 3, 'POS': 2, '``': 2, \"''\": 2, 'CD': 2, 'WRB': 1, 'VBZ': 1, 'NNS': 1, 'RBR': 1}), Counter({'NN': 55, 'JJ': 17, 'VB': 8, 'IN': 7, 'RB': 6, 'VBP': 5, ':': 5, 'PRP': 4, 'VBD': 3, 'VBZ': 3, 'WP': 2, 'JJS': 2, 'CC': 2, 'FW': 1, 'VBN': 1, '``': 1, \"''\": 1, 'POS': 1, 'MD': 1, 'DT': 1}), Counter({'NN': 6, 'JJ': 2, 'DT': 1, 'VB': 1, 'WRB': 1}), Counter({'NN': 26, 'RB': 11, 'JJ': 11, 'VBP': 7, 'VB': 7, 'VBD': 2, 'MD': 2, 'WRB': 1, 'CD': 1, 'POS': 1, 'PRP': 1, 'VBN': 1, 'NNS': 1}), Counter({'NN': 103, 'JJ': 43, 'VBP': 20, 'VB': 12, 'IN': 9, 'VBD': 8, 'DT': 8, 'RB': 7, 'NNS': 6, 'PRP': 5, 'VBN': 4, 'VBZ': 4, 'CC': 4, 'CD': 3, 'MD': 2, 'JJS': 2, 'VBG': 1, '``': 1, \"''\": 1, 'WRB': 1, 'FW': 1}), Counter({'NN': 57, 'JJ': 22, 'RB': 9, 'VBZ': 6, '``': 4, \"''\": 4, 'VBN': 3, 'POS': 3, 'VBP': 3, 'VB': 3, 'VBD': 2, 'DT': 2, ':': 2, 'JJS': 1, 'IN': 1, 'NNS': 1, 'VBG': 1, 'MD': 1, 'PRP': 1, 'FW': 1, 'NNP': 1}), Counter({'NN': 47, 'VBP': 11, 'VB': 11, 'JJ': 11, 'RB': 9, 'MD': 6, 'PRP': 4, 'IN': 4, 'NNS': 3, 'VBD': 3, 'VBZ': 3, 'JJS': 3, 'CD': 1, 'POS': 1, 'CC': 1}), Counter({'NN': 10, 'JJ': 2, 'DT': 1, 'CD': 1, 'POS': 1}), Counter({'NN': 15, 'JJ': 9, 'IN': 3, 'RB': 2, 'DT': 2, 'PRP': 1, 'VBN': 1, 'VBD': 1, 'NNS': 1, 'VBP': 1}), Counter({'NN': 17, 'JJ': 4, 'VBD': 2, 'VBP': 2, 'RB': 2, 'VB': 1}), Counter({'NN': 3, 'VB': 2, 'VBP': 1, 'JJ': 1}), Counter({'NN': 5, 'JJ': 3, 'VBP': 2, 'RB': 1, 'VB': 1, 'POS': 1, '``': 1, \"''\": 1, 'VBD': 1}), Counter({'NN': 16, 'JJ': 8, 'JJS': 4, 'RBS': 3, 'MD': 2, 'VB': 2, 'RB': 1, 'VBD': 1, 'NNS': 1, 'VBP': 1, 'IN': 1}), Counter({'NN': 30, 'VB': 10, 'JJ': 9, 'RB': 7, 'MD': 5, 'VBP': 4, 'DT': 2, 'IN': 2, 'POS': 2, 'TO': 1, 'NNS': 1, 'FW': 1, ':': 1, 'WRB': 1}), Counter({'NN': 99, 'JJ': 28, 'VBP': 6, 'RB': 6, 'IN': 6, 'DT': 4, 'VB': 4, 'VBD': 4, 'PRP': 4, 'VBZ': 4, 'CD': 2, ':': 2, 'MD': 1, 'VBN': 1, 'WP': 1, 'CC': 1, 'NNS': 1}), Counter({'NN': 37, 'JJ': 12, 'VBP': 5, 'VB': 5, 'POS': 4, 'VBD': 3, '``': 3, 'DT': 3, 'IN': 2, 'RB': 2, 'CC': 2, 'NNS': 1, 'WRB': 1, \"''\": 1, 'MD': 1, 'VBZ': 1, 'VBN': 1, 'CD': 1}), Counter({'NN': 78, 'JJ': 34, 'VBP': 6, 'RB': 6, 'FW': 4, 'IN': 4, 'VBD': 4, 'VB': 4, 'NNS': 3, 'POS': 2, 'VBN': 2, 'WP$': 2, '``': 1, \"''\": 1, 'RBR': 1, 'MD': 1}), Counter({'NN': 113, 'JJ': 29, 'VBP': 20, 'VB': 12, ':': 12, 'RB': 8, 'IN': 7, 'CC': 7, '``': 6, 'POS': 5, 'VBD': 5, 'DT': 4, 'VBZ': 4, 'VBN': 3, 'PRP': 3, 'NNS': 2, 'CD': 2, 'WP': 2, \"''\": 2, 'MD': 1, 'RP': 1, 'JJR': 1}), Counter({'NN': 50, 'JJ': 20, 'POS': 6, 'VBZ': 4, 'VBP': 4, 'PRP': 2, 'IN': 2, 'VBD': 2, 'WDT': 1, 'RB': 1, 'FW': 1, 'NNS': 1, 'CD': 1, 'JJS': 1, 'CC': 1}), Counter({'NN': 26, 'JJ': 14, 'VBD': 4, 'RB': 4, 'VBP': 2, 'PRP': 2, 'POS': 1, 'MD': 1, 'VB': 1, 'WP$': 1, 'IN': 1, '``': 1, \"''\": 1, 'CD': 1}), Counter({'NN': 16, 'JJ': 6, 'VBP': 3, 'VB': 3, 'RB': 2, 'VBN': 1, 'DT': 1, 'VBD': 1, 'MD': 1}), Counter({'NN': 41, 'JJ': 22, 'RB': 11, 'VBP': 7, 'POS': 6, 'VBZ': 5, 'CC': 4, 'DT': 4, 'VBD': 3, 'NNS': 3, 'WP': 2, 'PRP': 2, 'IN': 2, 'CD': 1, 'MD': 1, 'VB': 1, ':': 1, '``': 1, \"''\": 1, 'VBN': 1}), Counter({'NN': 37, 'JJ': 8, 'VBP': 5, 'RB': 4, 'DT': 3, 'VBD': 3, 'POS': 3, 'VB': 3, 'PRP': 1, 'JJR': 1, 'IN': 1, '``': 1, \"''\": 1, 'VBZ': 1, 'NNS': 1, 'MD': 1}), Counter({'NN': 68, 'JJ': 27, 'VBD': 13, 'VB': 6, 'PRP': 5, 'RB': 5, 'VBP': 3, 'MD': 3, 'CD': 3, 'VBZ': 2, 'RBR': 2, 'NNS': 2, 'JJS': 1, 'VBN': 1, 'WP': 1, 'IN': 1, 'DT': 1, 'RP': 1}), Counter({'NN': 30, 'JJ': 13, 'DT': 3, 'RB': 3, 'IN': 3, 'VBP': 3, 'VBD': 2, 'VBN': 1, 'CD': 1, 'MD': 1, 'VB': 1}), Counter({'NN': 10, 'DT': 1, 'JJ': 1, 'IN': 1}), Counter({'NN': 28, 'JJ': 7, 'PRP': 2, 'RB': 2, 'POS': 2, 'VBP': 1, 'VBD': 1, 'NNS': 1, 'DT': 1, 'IN': 1, 'JJS': 1, 'VB': 1})]\n",
            "The total verbs: 403\n",
            "The total nouns: 305\n",
            "The total adjectives: 233\n",
            "The total adverbs: 156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxtqmsG8Df08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "java_path = r'C:\\Program Files\\Java\\jdk1.8.0_102\\bin\\java.exe'\n",
        "os.environ['JAVAHOME'] = java_path\n",
        "\n",
        "from nltk.parse.stanford import StanfordParser\n",
        "scp = StanfordParser(path_to_jar='E:/stanford/stanford-parser-full-2015-04-20/stanford-parser.jar',\n",
        "                     path_to_models_jar='E:/stanford/stanford-parser-full-2015-04-20/stanford-parser-3.5.2-models.jar')\n",
        "                   \n",
        "result = list(scp.raw_parse(sentence))\n",
        "print(result[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "js_SPmnYXmMe",
        "colab_type": "code",
        "outputId": "7ffdb427-4cca-4b39-9981-3df0ee4dae5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\"\n",
        "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
        "  \"\"\")\n",
        "print(grammar1)\n",
        "for sent in cleaned_content:\n",
        "  rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
        "  for tree in rd_parser.parse(sent):\n",
        "     print(tree)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Grammar with 25 productions (start state = S)\n",
            "    S -> NP VP\n",
            "    VP -> V NP\n",
            "    VP -> V NP PP\n",
            "    PP -> P NP\n",
            "    V -> 'saw'\n",
            "    V -> 'ate'\n",
            "    V -> 'walked'\n",
            "    NP -> 'John'\n",
            "    NP -> 'Mary'\n",
            "    NP -> 'Bob'\n",
            "    NP -> Det N\n",
            "    NP -> Det N PP\n",
            "    Det -> 'a'\n",
            "    Det -> 'an'\n",
            "    Det -> 'the'\n",
            "    Det -> 'my'\n",
            "    N -> 'man'\n",
            "    N -> 'dog'\n",
            "    N -> 'cat'\n",
            "    N -> 'telescope'\n",
            "    N -> 'park'\n",
            "    P -> 'in'\n",
            "    P -> 'on'\n",
            "    P -> 'by'\n",
            "    P -> 'with'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dd81f27c92a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mrd_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursiveDescentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrammar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrd_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/parse/recursivedescent.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Start a recursive descent parse, with an initial tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             raise ValueError(\"Grammar does not cover some of the \"\n\u001b[0;32m--> 648\u001b[0;31m                              \"input words: %r.\" % missing)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calculate_grammar_forms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: '\\'i\\', \\'person\\', \\'hype\\', \\'claim\\', \\'masterpiec\\', \\'overreact\\', \\'overblown\\', \\'excit\\', \\'anoth\\', \\'joker\\', \\'base\\', \\'film\\', \\'i\\', \\'thought\\', \\'look\\', \\'solid\\', \\'best\\', \\'even\\', \\'bit\\', \\'pretenti\\', \\'trailer\\', \\'say\\', \\'i\\', \\'incred\\', \\'wrong\\', \\'thi\\', \\'massiv\\', \\'achiev\\', \\'cinema\\', \"\\'s\", \\'extrem\\', \\'rare\\', \\'day\\', \\'age\\', \\'cgi\\', \\'nonsens\\', \\'reboot\\', \\'while\\', \\'somewhat\\', \\'reboot\\', \\'sort\\', \\'standalon\\', \\'origin\\', \\'tale\\', \\'impecc\\', \\'start\\', \\'finish\\', \\'echo\\', \\'resembl\\', \\'best\\', \\'joker\\', \\'origin\\', \\'comic\\', \\'past\\', \\'joaquin\\', \\'bleed\\', \\'sweat\\', \\'cri\\', \\'everi\\', \\'drop\\', \\'magnific\\', \\'dedic\\', \\'perform\\', \\'heath\\', \\'ledger\\', \\'would\\', \\'proud\\', \\'thi\\', \\'undoubtedli\\', \\'greatest\\', \\'act\\', \\'perform\\', \\'sinc\\', \\'heath\\', \"\\'s\", \\'joker\\', \\'direct\\', \\'write\\', \\'slickli\\', \\'brilliant\\', \\'bleak\\', \\'set\\', \\'tone\\', \\'palpabl\\', \\'throughout\\', \\'when\\', \\'film\\', \\'place\\', \\'blown\\', \\'away\\', \\'everi\\', \\'audienc\\', \\'member\\', \\'awestruck\\', \\'wit\\', \\'film\\', \\'could\\', \\'still\\', \\'transport\\', \\'charact\\', \"\\'s\", \\'world\\', \\'exist\\', \\'believ\\', \\'hype\\', \\'thi\\', \\'go\\', \\'rever\\', \\'transcend\\', \\'masterpiec\\', \\'cinema\\''."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy",
        "colab_type": "text"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    }
  ]
}