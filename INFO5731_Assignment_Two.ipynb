{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/Huyen_INFO5731_Spring2020/blob/master/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9",
        "colab_type": "text"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF",
        "colab_type": "text"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k",
        "colab_type": "text"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
        "\n",
        "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
        "\n",
        "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 100 tweets by using hashtag [\"#wuhancoronovirus\"](https://twitter.com/hashtag/wuhancoronovirus) from Twitter. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3yu7AyECoO2",
        "colab_type": "text"
      },
      "source": [
        "**# The top 100 User Reviews of the film Joker from IMDB.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPjGGLvpVGE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 1:  Write a python program to collect text data and save the data into a csv file:\n",
        "\n",
        "# Import essential packages\n",
        "\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4HuTYm9D_7y",
        "colab_type": "code",
        "outputId": "41f9c07a-ade2-4071-a9d3-804d4fd36f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Request page to get content\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "session = requests.Session()\n",
        "host_url = 'https://www.imdb.com/title/tt7286456/reviews'\n",
        "get_webpage = session.get(host_url)\n",
        "res_host = BeautifulSoup(get_webpage.content, 'html.parser')\n",
        "\n",
        "# Find key of load-more pages\n",
        "key = res_host.find('div', {'class':'load-more-data'})\n",
        "datakey = key.attrs['data-key']\n",
        "\n",
        "# Generate urls by found keys \n",
        "# Request to continue to get next-page key\n",
        "loadmore_url_list = []\n",
        "a = True\n",
        "while a:\n",
        "    if key is None:\n",
        "        print('error')\n",
        "        a = False\n",
        "    else:\n",
        "        loadmore_url = 'https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey='+datakey\n",
        "        get_loadmore = session.get(loadmore_url)\n",
        "        res_loadmore = BeautifulSoup(get_loadmore.content, 'html.parser')\n",
        "        key = res_loadmore.find('div', {'class':'load-more-data'})\n",
        "        datakey = key.attrs['data-key']\n",
        "        loadmore_url_list.append('https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey='+datakey)\n",
        "        if len(loadmore_url_list) ==4: # need 4 urls to find around 100 reviews, then stop\n",
        "          break\n",
        "print(loadmore_url_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbfqe5diyik76uh5mjrrpumsabhzfmxvlnomwklyczuf43o6ss6oe4ftmjndf4k4x4tpwcua64xxqd6tpumgltcoyq', 'https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbjqmytc3ya66vx5mrqrltm4ar4y4hhzo5ziwr26fbyhvrl4ty4ouyflmrcd5vndtswzhodoodfhdusfc66yq5ewbxf', 'https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbpqqzd6zqd7kxh5mbtrptmqbzyy4hhzo5ziwr26fbyhvrl4ty4ouyfxnrlcvv5dtsk3h5rcotmtpasw6kcl2klcdpx', 'https://www.imdb.com/title/tt7286456/reviews/_ajax?ref_=undefined&paginationKey=g4wp7cbnqqztayaf7ctxrnjsrxt4wbr4y4hhzo5ziwr26fbyhvrl4ty4ouzvxmrcdbr5dtxt545gfko46fiaetgrwtzzoi2e']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzMjKmiPTHlH",
        "colab_type": "code",
        "outputId": "fdce8e4f-f411-4781-b8af-d732d390d213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "# Create a list of all urls, including urls in host and next pages, which will be using\n",
        "host_url = 'https://www.imdb.com/title/tt7286456/reviews'\n",
        "all_urls=[]\n",
        "all_urls.append(host_url)\n",
        "all_urls.extend(loadmore_url_list)\n",
        "\n",
        "review_elements = []\n",
        "for url in all_urls:\n",
        "  request = urllib.request.urlopen (url)\n",
        "  webpage  = request.read()\n",
        "  soup = BeautifulSoup(webpage)\n",
        "\n",
        "  reviews = soup.find_all(\"div\", {\"class\":\"lister-item-content\" })\n",
        "  for review in reviews:\n",
        "    try:\n",
        "        review_title = review.find(\"a\", class_=\"title\").text.strip()\n",
        "    except:\n",
        "        review_title = \"\"\n",
        "    try:\n",
        "        review_id = review.find(\"a\")[\"href\"].split(\"/\")[2]\n",
        "    except:\n",
        "        review_id = \"\"\n",
        "    try:\n",
        "        review_date = review.find(\"span\", class_=\"review-date\").get_text()\n",
        "    except:\n",
        "        review_date = \"\"\n",
        "    try:\n",
        "        review_nickname = review.find (\"span\", class_=\"display-name-link\").get_text()\n",
        "    except:\n",
        "        review_nickname = \"\"\n",
        "    try:\n",
        "        review_content = review.find (\"div\", class_=\"text show-more__control\").get_text()\n",
        "    except:\n",
        "        review_content =\"\"\n",
        "    #print(review_content)\n",
        "    try:\n",
        "        review_rating = review. find (\"span\", class_=\"rating-other-user-rating\").getText().strip()\n",
        "        #print(review_rating)\n",
        "    except:\n",
        "        review_rating = \"\"\n",
        "    try:\n",
        "        review_helpfulness = review.find(\"div\", {\"class\": \"actions text-muted\"}).text.split(\"\\n\")[1]\n",
        "        #print(review_helpfulness)\n",
        "    except:\n",
        "        review_helpfulness = \"\"\n",
        "\n",
        "    review_elements.append([review_title, review_id, review_date, review_nickname, review_content, review_rating, review_helpfulness])\n",
        "#print(len(review_elements))\n",
        "\n",
        "df = pd.DataFrame(review_elements, columns=[\"review_title\", \"review_id\", \"review_date\", \"review_nickname\", \"review_content\", \"review_rating\", \"review_helpfulness\"])\n",
        "df\n",
        "with open(\"E:\\Helen\\INFO5731_Assignment2\\Joke_reviews.csv\", \"w\", newline=\"\", encoding='utf-8') as file:\n",
        "  df.to_csv(file)\n",
        "with open(\"E:\\Helen\\INFO5731_Assignment2\\Joke_reviews.csv\", \"r\", encoding='utf-8') as file:\n",
        "  pd.read_csv(file)\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_title</th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_nickname</th>\n",
              "      <th>review_content</th>\n",
              "      <th>review_rating</th>\n",
              "      <th>review_helpfulness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As a viewer that actually went to TIFF and wit...</td>\n",
              "      <td>rw5112402</td>\n",
              "      <td>10 September 2019</td>\n",
              "      <td>JF500</td>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6,851 out of 7,877 found t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Outstanding movie with a haunting performance ...</td>\n",
              "      <td>rw5159304</td>\n",
              "      <td>3 October 2019</td>\n",
              "      <td>MihaVrhunc</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>3,384 out of 4,052 found t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Only certain people can relate</td>\n",
              "      <td>rw5168360</td>\n",
              "      <td>7 October 2019</td>\n",
              "      <td>lesterarnoldpinto</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>2,688 out of 3,322 found t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Must have put a SMILE of Satisfaction on Heath...</td>\n",
              "      <td>rw5092831</td>\n",
              "      <td>1 September 2019</td>\n",
              "      <td>Chandler_Bing_</td>\n",
              "      <td>Truly a masterpiece, The Best film of 2019, on...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>3,172 out of 3,945 found t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Hype is real</td>\n",
              "      <td>rw5160204</td>\n",
              "      <td>4 October 2019</td>\n",
              "      <td>kdagoulis26</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>2,358 out of 2,928 found t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>Masterpiece</td>\n",
              "      <td>rw5483534</td>\n",
              "      <td>14 February 2020</td>\n",
              "      <td>mshazadsameem</td>\n",
              "      <td>After seeing the trailer, something told me th...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6 out of 8 found this help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>Outstanding in every way</td>\n",
              "      <td>rw5459340</td>\n",
              "      <td>4 February 2020</td>\n",
              "      <td>m-fadelli</td>\n",
              "      <td>Acting, story, photography, music everything i...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6 out of 8 found this help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>Sticks much deeper than you expect</td>\n",
              "      <td>rw5454618</td>\n",
              "      <td>2 February 2020</td>\n",
              "      <td>fasilhayat</td>\n",
              "      <td>Philosphical approach and giving a viewer an i...</td>\n",
              "      <td>9/10</td>\n",
              "      <td>6 out of 8 found this help...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>10/10</td>\n",
              "      <td>rw5092944</td>\n",
              "      <td>1 September 2019</td>\n",
              "      <td>bada-65197</td>\n",
              "      <td>The Joker won. Absolutely tremendous, what act...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>125 out of 267 found this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>A decent performance by Joaquin Pheonix sadly ...</td>\n",
              "      <td>rw5162673</td>\n",
              "      <td>5 October 2019</td>\n",
              "      <td>ITS_SHOWTIME37</td>\n",
              "      <td>After seeing the billboard signs all around th...</td>\n",
              "      <td>3/10</td>\n",
              "      <td>61 out of 123 found this h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          review_title  ...                                 review_helpfulness\n",
              "0    As a viewer that actually went to TIFF and wit...  ...                      6,851 out of 7,877 found t...\n",
              "1    Outstanding movie with a haunting performance ...  ...                      3,384 out of 4,052 found t...\n",
              "2                       Only certain people can relate  ...                      2,688 out of 3,322 found t...\n",
              "3    Must have put a SMILE of Satisfaction on Heath...  ...                      3,172 out of 3,945 found t...\n",
              "4                                     The Hype is real  ...                      2,358 out of 2,928 found t...\n",
              "..                                                 ...  ...                                                ...\n",
              "103                                        Masterpiece  ...                      6 out of 8 found this help...\n",
              "104                           Outstanding in every way  ...                      6 out of 8 found this help...\n",
              "105                 Sticks much deeper than you expect  ...                      6 out of 8 found this help...\n",
              "106                                              10/10  ...                      125 out of 267 found this ...\n",
              "107  A decent performance by Joaquin Pheonix sadly ...  ...                      61 out of 123 found this h...\n",
              "\n",
              "[108 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab_type": "code",
        "outputId": "2e6f4523-15de-4acc-f0a2-4af984fc065d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        }
      },
      "source": [
        "# Write your code here\n",
        "#clean the text data\n",
        "from __future__ import division\n",
        "import nltk # re, pprint\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import string \n",
        "\n",
        "with open(\"E:\\Helen\\INFO5731_Assignment2\\Joke_reviews.csv\", \"r\", encoding='utf-8') as file:\n",
        "  data = pd.read_csv(file)\n",
        "\n",
        "raw_title = [str(line) for line in data.review_title]\n",
        "raw_content = [str(line) for line in data.review_content]\n",
        "# Tokenize raw text in raw_title and raw_content\n",
        "tokens_title= [nltk.word_tokenize(title) for title in raw_title]\n",
        "tokens_content = [nltk.word_tokenize(item) for item in raw_content]\n",
        "\n",
        "# PROCCESSES OF CLEANING TEXT  \n",
        "def cleaning_text (text):\n",
        "    step1 = remove_noise(text)\n",
        "    step2 = remove_num (step1)\n",
        "    step3 = remove_stop (step2)\n",
        "    step4 = lowercase (step3)\n",
        "    step5 = stemming (step4)\n",
        "    step6 = lemma (step5)\n",
        "    return step6\n",
        "\n",
        "# (1) Remove noise, such as special characters and punctuations.      \n",
        "def remove_noise (list):\n",
        "    punct=[char for char in string.punctuation]\n",
        "    noise_removed = [word for word in list if word not in punct]\n",
        "    return noise_removed\n",
        "\n",
        "#(2) Remove numbers.\n",
        "def remove_num (list):\n",
        "    num_removed  = [word for word in list if not word.isnumeric()]\n",
        "    return num_removed\n",
        "\n",
        " # (3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "def remove_stop (list):\n",
        "    stopword_removed = [word for word in list if word not in stopwords.words('english')]\n",
        "    return stopword_removed\n",
        "\n",
        "#(4) Lowercase all texts\n",
        "def lowercase (list):\n",
        "    lowercase = [word.lower() for word in list]\n",
        "    return lowercase\n",
        "# (5) Stemming\n",
        "def stemming (list):\n",
        "    ps = PorterStemmer()\n",
        "    word_stemmed = [ps.stem(word) for word in list]\n",
        "    return word_stemmed\n",
        "# (6) Lemmatization.\n",
        "def lemma (list):\n",
        "    wnl =  WordNetLemmatizer ()\n",
        "    word_lemmatized = [wnl.lemmatize(word) for word in list]\n",
        "    return word_lemmatized\n",
        "\n",
        "# Cleaning title reviews and content review\n",
        "cleaned_title = [cleaning_text (sublist) for sublist in tokens_title]\n",
        "cleaned_content = [cleaning_text (sublist) for sublist in tokens_content]\n",
        "# Save cleaned text into new columns in dataframe\n",
        "df[\"cleaned_title\"] = cleaned_title\n",
        "df[\"cleaned_content\"] = cleaned_content\n",
        "df\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_title</th>\n",
              "      <th>review_id</th>\n",
              "      <th>review_date</th>\n",
              "      <th>review_nickname</th>\n",
              "      <th>review_content</th>\n",
              "      <th>review_rating</th>\n",
              "      <th>review_helpfulness</th>\n",
              "      <th>cleaned_title</th>\n",
              "      <th>cleaned_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As a viewer that actually went to TIFF and wit...</td>\n",
              "      <td>rw5112402</td>\n",
              "      <td>10 September 2019</td>\n",
              "      <td>JF500</td>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6,851 out of 7,877 found t...</td>\n",
              "      <td>[a, viewer, actual, went, tiff, wit, film, n't...</td>\n",
              "      <td>[i, person, saw, hype, claim, masterpiec, over...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Outstanding movie with a haunting performance ...</td>\n",
              "      <td>rw5159304</td>\n",
              "      <td>3 October 2019</td>\n",
              "      <td>MihaVrhunc</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>3,384 out of 4,052 found t...</td>\n",
              "      <td>[outstand, movi, haunt, perform, best, charact...</td>\n",
              "      <td>[everi, movi, come, truli, make, impact, joaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Only certain people can relate</td>\n",
              "      <td>rw5168360</td>\n",
              "      <td>7 October 2019</td>\n",
              "      <td>lesterarnoldpinto</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>2,688 out of 3,322 found t...</td>\n",
              "      <td>[onli, certain, peopl, relat]</td>\n",
              "      <td>[thi, movi, felt, alon, isol, truli, relat, yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Must have put a SMILE of Satisfaction on Heath...</td>\n",
              "      <td>rw5092831</td>\n",
              "      <td>1 September 2019</td>\n",
              "      <td>Chandler_Bing_</td>\n",
              "      <td>Truly a masterpiece, The Best film of 2019, on...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>3,172 out of 3,945 found t...</td>\n",
              "      <td>[must, put, smile, satisfact, heath, ledger, '...</td>\n",
              "      <td>[truli, masterpiec, the, best, film, one, best...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Hype is real</td>\n",
              "      <td>rw5160204</td>\n",
              "      <td>4 October 2019</td>\n",
              "      <td>kdagoulis26</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>2,358 out of 2,928 found t...</td>\n",
              "      <td>[the, hype, real]</td>\n",
              "      <td>[most, time, movi, anticip, like, end, fall, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>Masterpiece</td>\n",
              "      <td>rw5483534</td>\n",
              "      <td>14 February 2020</td>\n",
              "      <td>mshazadsameem</td>\n",
              "      <td>After seeing the trailer, something told me th...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6 out of 8 found this help...</td>\n",
              "      <td>[masterpiec]</td>\n",
              "      <td>[after, see, trailer, someth, told, go, master...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>Outstanding in every way</td>\n",
              "      <td>rw5459340</td>\n",
              "      <td>4 February 2020</td>\n",
              "      <td>m-fadelli</td>\n",
              "      <td>Acting, story, photography, music everything i...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>6 out of 8 found this help...</td>\n",
              "      <td>[outstand, everi, way]</td>\n",
              "      <td>[act, stori, photographi, music, everyth, dawn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>Sticks much deeper than you expect</td>\n",
              "      <td>rw5454618</td>\n",
              "      <td>2 February 2020</td>\n",
              "      <td>fasilhayat</td>\n",
              "      <td>Philosphical approach and giving a viewer an i...</td>\n",
              "      <td>9/10</td>\n",
              "      <td>6 out of 8 found this help...</td>\n",
              "      <td>[stick, much, deeper, expect]</td>\n",
              "      <td>[philosph, approach, give, viewer, insight, in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>10/10</td>\n",
              "      <td>rw5092944</td>\n",
              "      <td>1 September 2019</td>\n",
              "      <td>bada-65197</td>\n",
              "      <td>The Joker won. Absolutely tremendous, what act...</td>\n",
              "      <td>10/10</td>\n",
              "      <td>125 out of 267 found this ...</td>\n",
              "      <td>[10/10]</td>\n",
              "      <td>[the, joker, absolut, tremend, act, skill, tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>A decent performance by Joaquin Pheonix sadly ...</td>\n",
              "      <td>rw5162673</td>\n",
              "      <td>5 October 2019</td>\n",
              "      <td>ITS_SHOWTIME37</td>\n",
              "      <td>After seeing the billboard signs all around th...</td>\n",
              "      <td>3/10</td>\n",
              "      <td>61 out of 123 found this h...</td>\n",
              "      <td>[a, decent, perform, joaquin, pheonix, sadli, ...</td>\n",
              "      <td>[after, see, billboard, sign, around, london, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          review_title  ...                                    cleaned_content\n",
              "0    As a viewer that actually went to TIFF and wit...  ...  [i, person, saw, hype, claim, masterpiec, over...\n",
              "1    Outstanding movie with a haunting performance ...  ...  [everi, movi, come, truli, make, impact, joaqu...\n",
              "2                       Only certain people can relate  ...  [thi, movi, felt, alon, isol, truli, relat, yo...\n",
              "3    Must have put a SMILE of Satisfaction on Heath...  ...  [truli, masterpiec, the, best, film, one, best...\n",
              "4                                     The Hype is real  ...  [most, time, movi, anticip, like, end, fall, s...\n",
              "..                                                 ...  ...                                                ...\n",
              "103                                        Masterpiece  ...  [after, see, trailer, someth, told, go, master...\n",
              "104                           Outstanding in every way  ...  [act, stori, photographi, music, everyth, dawn...\n",
              "105                 Sticks much deeper than you expect  ...  [philosph, approach, give, viewer, insight, in...\n",
              "106                                              10/10  ...  [the, joker, absolut, tremend, act, skill, tal...\n",
              "107  A decent performance by Joaquin Pheonix sadly ...  ...  [after, see, billboard, sign, around, london, ...\n",
              "\n",
              "[108 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV",
        "colab_type": "text"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "colab_type": "code",
        "outputId": "7c308d13-821c-4fe4-bccf-c0ff89c2c872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Write your code here\n",
        "#(1) Tag parts of Speech (POS) and  calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb)...\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from collections import Counter\n",
        "count_POStag = []\n",
        "for tokens in cleaned_title:\n",
        "    title_tagged = nltk.pos_tag(tokens)\n",
        "    count_POStag.append(Counter (tag for tokens, tag in title_tagged))\n",
        "for tokens in cleaned_content:\n",
        "    content_tagged = nltk.pos_tag(tokens)\n",
        "    count_POStag. append (Counter (tag for tokens, tag in content_tagged))\n",
        "    \n",
        "print(count_POStag)\n",
        "count_VB=0\n",
        "count_NN=0\n",
        "count_ADJ=0\n",
        "count_ADV=0\n",
        "for pack in count_POStag:\n",
        "  for item in pack:\n",
        "    if item ==\"VB\" or item==\"VBG\" or item==\"VBD\" or item==\"VBP\" or item==\"VBZ\":\n",
        "      count_VB+=1\n",
        "    elif item ==\"NN\" or item==\"NNS\" or item ==\"NNP\" or item==\"NNPS\":\n",
        "      count_NN+=1\n",
        "    elif item ==\"JJ\" or item ==\"JJR\" or item==\"JJS\":\n",
        "      count_ADJ+=1\n",
        "    elif item ==\"RB\" or item==\"RBR\" or item==\"RBS\":\n",
        "      count_ADV+=1\n",
        "    else:\n",
        "      pass\n",
        "print(\"The total verbs:\", count_VB)\n",
        "print(\"The total nouns:\", count_NN)\n",
        "print(\"The total adjectives:\", count_ADJ)\n",
        "print(\"The total adverbs:\", count_ADV)\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[Counter({'NN': 9, 'JJ': 3, 'DT': 1, 'VBD': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 5, 'JJS': 1, 'VB': 1, 'RB': 1, 'VBN': 1}), Counter({'NN': 3, 'JJ': 1}), Counter({'NN': 4, 'RB': 2, 'MD': 1, 'VB': 1, 'JJ': 1, 'POS': 1}), Counter({'DT': 1, 'NN': 1, 'JJ': 1}), Counter({'NN': 2}), Counter({'RB': 1, 'VB': 1, 'WRB': 1, 'JJ': 1, 'VBP': 1}), Counter({'NN': 2, 'VBD': 1, 'JJ': 1}), Counter({'NN': 3, 'DT': 1, 'RB': 1, 'VBD': 1}), Counter({'NN': 6, 'POS': 1, 'JJS': 1, 'VBZ': 1, ':': 1, 'VBD': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'JJ': 2, 'NN': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 2}), Counter({'NN': 4, 'RB': 2, 'VB': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 2}), Counter({'NN': 2, 'MD': 1, 'VB': 1}), Counter({'VB': 2, 'VBP': 1, 'RB': 1}), Counter({'NN': 3, 'CD': 1, 'JJS': 1, 'VBP': 1, 'RB': 1, 'VBN': 1}), Counter({'NN': 2}), Counter({'IN': 1}), Counter({'NN': 2}), Counter({'IN': 1, 'DT': 1, 'NN': 1}), Counter({'NN': 1}), Counter({'NN': 2, 'VB': 1}), Counter({'WP': 1, 'VBZ': 1, 'JJ': 1, 'NN': 1}), Counter({'NN': 2, 'JJS': 1, 'IN': 1, 'DT': 1}), Counter({'NN': 2}), Counter({'NN': 1, 'POS': 1, 'PRP': 1}), Counter({'NN': 2}), Counter({'RB': 1, 'JJ': 1}), Counter({'NN': 2, 'RB': 1}), Counter({'RB': 1, 'JJ': 1, 'NN': 1}), Counter({'NN': 3, 'JJ': 1}), Counter({'NN': 1}), Counter({'VBD': 1, 'RB': 1}), Counter({'NN': 2}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 1, 'VBP': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 4, 'VBD': 1, 'IN': 1}), Counter({'NN': 6, 'IN': 1, 'JJS': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'DT': 1, 'NN': 1}), Counter({'NN': 2}), Counter({'NN': 2, 'DT': 1}), Counter({'NN': 2}), Counter({'RB': 1, 'NN': 1}), Counter({'NN': 3}), Counter({'NN': 2, 'JJ': 1}), Counter({'NN': 2}), Counter({'NN': 2}), Counter({'NN': 1}), Counter({'NNS': 1, 'NN': 1}), Counter({'NN': 4, 'POS': 1}), Counter({'NN': 2, 'CC': 1}), Counter({'NN': 5, 'IN': 1, 'RB': 1, 'JJS': 1, 'JJ': 1}), Counter({'VBP': 1, 'JJ': 1, 'CD': 1, 'RB': 1, 'IN': 1, 'VB': 1}), Counter({'NN': 3, 'VBP': 1, 'RB': 1}), Counter({'NN': 1}), Counter({'JJ': 2, 'NN': 2, 'DT': 1}), Counter({'NN': 1}), Counter({'NN': 1, 'VBD': 1}), Counter({'NN': 2}), Counter({'NN': 4, 'JJ': 2}), Counter({'CD': 1, 'DT': 1, 'JJS': 1, 'NN': 1, 'RB': 1}), Counter({'NN': 4, 'JJ': 1, ':': 1}), Counter({'NN': 1}), Counter({'JJ': 2, 'NN': 2, '``': 1, 'JJS': 1, 'RB': 1, \"''\": 1, 'NNS': 1}), Counter({'NN': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'PRP': 1, 'VBP': 1, 'JJ': 1, 'NN': 1}), Counter({'NN': 3, 'VBD': 1, 'JJ': 1}), Counter({'IN': 1, 'NN': 1, 'CD': 1}), Counter({'NN': 3, 'VBP': 1}), Counter({'NN': 1}), Counter({'NN': 4, 'DT': 1, 'JJ': 1}), Counter({'NNS': 1, 'VBP': 1}), Counter({'NN': 4, 'RB': 1, 'VBD': 1, 'CD': 1}), Counter({'NN': 2}), Counter({'IN': 2, 'NN': 2}), Counter({'NN': 2, 'DT': 1}), Counter({'VBP': 1, 'RB': 1, 'VB': 1, 'NN': 1}), Counter({'JJ': 1, 'NN': 1, ':': 1}), Counter({'JJS': 1, 'NN': 1, 'VBN': 1, 'NNS': 1}), Counter({'JJ': 1, 'NN': 1}), Counter({'NN': 2, ':': 1}), Counter({'NN': 1}), Counter({'JJS': 1, 'NN': 1, 'RB': 1}), Counter({'NN': 3, 'RB': 2, 'JJ': 2, 'VBP': 2, 'IN': 1, 'VBD': 1, 'NNS': 1, 'VB': 1}), Counter({'NN': 3, 'RB': 2, 'DT': 1, 'JJ': 1}), Counter({'RB': 2}), Counter({'NN': 6, 'JJ': 2}), Counter({'NN': 2}), Counter({'RBR': 1, 'RB': 1, 'VBD': 1}), Counter({'NN': 6, 'VBN': 1}), Counter({'NN': 9, 'VBP': 1, 'JJ': 1}), Counter({'NN': 5, 'JJ': 1}), Counter({'NN': 1}), Counter({'NN': 2, 'WRB': 1, 'JJ': 1, 'VBP': 1}), Counter({'NN': 2}), Counter({'RB': 1, 'JJ': 1, 'NN': 1}), Counter({'NN': 1}), Counter({'NN': 2, 'DT': 1}), Counter({'RB': 1, 'JJ': 1, 'JJR': 1, 'NN': 1}), Counter({'CD': 1}), Counter({'NN': 6, 'JJ': 2, 'DT': 1, 'VBD': 1}), Counter({'NN': 57, 'JJ': 19, 'VBP': 7, 'RB': 6, 'VB': 3, 'NNS': 3, 'VBN': 3, 'POS': 3, 'VBD': 2, 'DT': 2, 'IN': 2, 'JJS': 2, 'MD': 2, 'VBZ': 1, 'WRB': 1}), Counter({'NN': 26, 'JJ': 10, 'RB': 4, 'VBP': 3, 'POS': 3, 'NNS': 1, ':': 1, 'MD': 1, 'VB': 1, 'VBD': 1, 'JJS': 1, 'VBN': 1}), Counter({'NN': 18, 'JJ': 9, 'VBP': 5, 'NNS': 2, 'VBD': 1, 'PRP': 1, 'DT': 1, 'CC': 1, 'CD': 1, 'RBR': 1, 'IN': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 20, 'JJ': 8, 'JJS': 3, 'VB': 2, 'VBP': 2, 'VBZ': 1, 'DT': 1, 'CD': 1, ':': 1, 'CC': 1, 'VBG': 1, 'RB': 1}), Counter({'NN': 26, 'JJ': 10, 'VBP': 4, 'JJS': 2, 'NNS': 2, 'IN': 2, '``': 2, \"''\": 2, 'RB': 2, 'PRP': 1, 'VBN': 1, 'JJR': 1, 'VBZ': 1, 'DT': 1}), Counter({'NN': 27, 'JJ': 9, 'IN': 4, 'POS': 4, 'DT': 3, 'VBD': 3, 'VB': 2, 'VBP': 2, 'FW': 1, 'PRP': 1, 'VBZ': 1}), Counter({'NN': 27, 'JJ': 19, 'VBP': 8, 'RB': 8, 'VB': 7, 'CC': 4, 'DT': 3, 'VBD': 3, 'RBS': 2, 'NNS': 1, 'MD': 1, 'VBN': 1, 'VBZ': 1, 'IN': 1, 'PRP': 1, 'VBG': 1, 'JJS': 1}), Counter({'NN': 19, 'VB': 4, 'VBP': 3, 'JJ': 3, 'PRP': 1, 'VBZ': 1, 'FW': 1, 'MD': 1, 'POS': 1, 'CC': 1, 'RB': 1, 'DT': 1, 'IN': 1}), Counter({'NN': 77, 'JJ': 37, 'RB': 7, 'POS': 6, 'VBP': 5, 'VB': 4, 'IN': 3, 'PRP': 3, 'MD': 3, 'JJS': 3, 'VBN': 2, 'VBZ': 2, 'CC': 1, 'VBD': 1, 'DT': 1, 'NNS': 1, 'CD': 1, 'WP': 1}), Counter({'NN': 29, 'JJ': 14, 'VB': 6, 'VBZ': 3, 'VBP': 2, 'VBD': 2, 'RB': 2, 'PRP': 1, 'POS': 1, 'CC': 1, 'NNP': 1, 'TO': 1, 'RP': 1, 'JJS': 1}), Counter({'NN': 20, 'JJ': 13, 'RB': 9, 'VB': 7, 'VBP': 5, 'MD': 2, 'NNS': 1, 'VBD': 1, 'CD': 1, '``': 1, \"''\": 1}), Counter({'NN': 31, 'JJ': 14, 'VBP': 6, 'VBD': 5, 'RB': 5, 'NNS': 3, 'VB': 3, 'PRP': 2, 'IN': 2, 'DT': 1, '``': 1, \"''\": 1, 'VBZ': 1, 'MD': 1, 'JJS': 1}), Counter({'NN': 10, 'JJ': 2, 'VBP': 2, 'DT': 1, 'NNS': 1}), Counter({'NN': 7, 'JJ': 2, 'VBP': 1}), Counter({'NN': 4, 'JJ': 3, 'DT': 1, 'VBP': 1, 'RB': 1}), Counter({'NN': 65, 'JJ': 32, 'VBD': 9, 'VB': 6, 'VBP': 5, 'IN': 3, 'RB': 3, 'MD': 3, 'DT': 2, ':': 1, 'WDT': 1, 'WP': 1, 'TO': 1, 'NNS': 1, 'CC': 1}), Counter({'NN': 34, 'JJ': 10, 'VBP': 4, 'NNS': 2, 'RB': 2, 'POS': 2, 'VB': 1, 'PRP': 1, 'IN': 1}), Counter({'NN': 81, 'JJ': 36, 'RB': 16, 'VBD': 14, 'VB': 12, 'VBP': 9, 'VBN': 4, 'MD': 4, 'POS': 4, 'PRP': 4, 'VBZ': 4, 'DT': 3, 'IN': 3, 'CD': 2, ':': 1, 'EX': 1, 'WP': 1, 'NNS': 1, 'CC': 1}), Counter({'NN': 89, 'JJ': 39, 'VBP': 12, 'VB': 10, 'RB': 8, 'POS': 7, 'NNS': 4, 'VBZ': 3, 'IN': 3, 'CD': 3, 'MD': 2, 'JJS': 2, 'VBD': 2, 'PRP': 1, 'VBN': 1, 'VBG': 1}), Counter({'NN': 40, 'JJ': 15, 'VBP': 7, 'VBN': 4, 'VBD': 3, 'IN': 3, 'DT': 3, 'VBZ': 2, 'NNS': 2, 'POS': 2, 'RB': 2, 'FW': 1, 'JJS': 1, 'VB': 1, 'CD': 1, 'RBR': 1, 'PRP': 1, 'MD': 1}), Counter({'NN': 38, 'JJ': 18, 'VB': 4, 'RB': 4, 'VBP': 4, 'VBD': 3, 'CC': 2, 'IN': 2, 'NNS': 1, 'MD': 1, 'DT': 1, 'RBR': 1}), Counter({'NN': 32, 'JJ': 8, 'VBP': 6, 'IN': 5, 'VB': 4, 'RB': 3, 'CD': 3, 'VBD': 2, 'DT': 1, 'MD': 1, 'POS': 1}), Counter({'NN': 27, 'JJ': 11, 'VBP': 8, ':': 3, 'IN': 3, 'VBD': 2, 'VBN': 2, 'CC': 1, 'JJS': 1, 'POS': 1, 'RBR': 1, 'RB': 1, 'MD': 1, 'VB': 1}), Counter({'NN': 33, 'VBP': 5, 'JJ': 5, 'VB': 4, 'RB': 4, 'NNS': 4, 'VBD': 4, 'CD': 3, 'PRP$': 1, 'TO': 1, 'JJS': 1, 'DT': 1, 'PRP': 1}), Counter({'NN': 32, 'JJ': 13, 'DT': 5, 'VB': 3, 'VBP': 3, 'NNS': 2, 'RB': 2, 'VBD': 2, 'IN': 2, 'MD': 2, 'POS': 1}), Counter({'NN': 19, 'JJ': 7, ':': 3, 'DT': 2, 'VBP': 2, 'POS': 1, 'CC': 1, 'IN': 1, 'VB': 1, 'JJS': 1, 'WP': 1}), Counter({'NN': 19, 'JJ': 13, 'RB': 4, 'VBD': 3, 'VBP': 2, 'VB': 2, 'NNS': 1, 'PRP': 1, 'CC': 1, 'VBN': 1}), Counter({'NN': 11, 'VBP': 2, 'JJ': 2, 'DT': 1, 'POS': 1, 'VBN': 1}), Counter({'NN': 10, 'JJ': 5, 'RB': 2, 'VBP': 2, 'VBD': 1}), Counter({'NN': 139, 'JJ': 42, 'VBP': 19, 'RB': 17, 'VB': 12, 'VBD': 10, 'IN': 9, 'CD': 8, 'POS': 5, 'VBZ': 5, 'MD': 4, 'PRP': 3, 'VBN': 3, 'RBR': 2, 'NNS': 2, 'DT': 2, 'FW': 1, 'JJR': 1, 'EX': 1, 'RBS': 1, 'JJS': 1, 'PDT': 1, 'NNP': 1}), Counter({'NN': 26, 'VBP': 6, 'JJ': 5, 'VB': 2, 'POS': 2, 'VBZ': 1, 'RB': 1}), Counter({'NN': 14, 'RB': 4, 'VB': 4, 'VBP': 3, 'JJ': 3, ':': 2, 'VBD': 2, 'JJS': 1, 'VBN': 1, 'MD': 1, 'IN': 1, 'CC': 1, 'CD': 1}), Counter({'NN': 1}), Counter({'NN': 9, 'VBN': 1, 'VBZ': 1, 'PRP': 1, 'JJ': 1}), Counter({'NN': 13, 'JJ': 5, 'IN': 4, 'RB': 2, 'DT': 2, 'VBP': 1, 'VBN': 1, 'FW': 1, 'VB': 1, 'VBZ': 1}), Counter({'NN': 9, 'JJ': 5, 'VBD': 3, 'MD': 2, 'VB': 2, ':': 2, 'VBN': 2, 'DT': 1, 'PRP': 1, 'RB': 1, 'VBP': 1}), Counter({'NN': 2, 'PRP': 1, 'VBZ': 1, 'JJR': 1, 'MD': 1, 'RB': 1, 'VB': 1}), Counter({'NN': 4, 'JJS': 1, 'JJ': 1, 'VBP': 1}), Counter({'NN': 29, 'JJ': 4, 'VBP': 4, 'VBD': 3, 'IN': 2, 'RB': 2, 'PRP': 1, 'VBZ': 1, 'VBN': 1, 'NNS': 1, 'MD': 1, 'VB': 1, 'DT': 1, 'POS': 1}), Counter({'NN': 13, 'DT': 2, 'VBZ': 2, 'JJ': 2, 'RB': 1, 'VBN': 1, 'VBD': 1, 'RBR': 1, 'IN': 1}), Counter({'NN': 94, 'JJ': 30, 'VBP': 15, 'RB': 14, 'IN': 9, 'DT': 7, 'VBD': 6, 'NNS': 6, 'VBZ': 5, 'POS': 4, 'VB': 4, 'FW': 3, 'PRP': 2, 'EX': 1, 'JJR': 1, 'CC': 1}), Counter({'NN': 44, 'JJ': 16, 'VBP': 13, 'RB': 6, 'VB': 3, 'DT': 3, 'IN': 3, 'VBN': 2, 'VBD': 2, 'VBZ': 2, 'PRP': 1, 'NNS': 1, 'POS': 1, 'EX': 1, 'RBR': 1}), Counter({'NN': 82, 'JJ': 36, 'VBP': 11, 'RB': 8, 'VBD': 7, 'IN': 6, 'POS': 5, 'VBN': 3, 'DT': 3, 'VB': 3, 'CD': 2, 'JJS': 2, 'MD': 2, 'NNS': 2, 'PRP': 1, 'CC': 1}), Counter({'NN': 37, 'JJ': 22, 'VBP': 6, 'IN': 5, 'VB': 4, 'DT': 3, 'CD': 3, 'NNS': 2, 'VBN': 2, 'POS': 2, 'CC': 2, 'RB': 2, 'MD': 1, 'JJS': 1}), Counter({'NN': 45, 'JJ': 8, 'VBP': 5, 'IN': 4, 'DT': 4, 'VB': 3, 'FW': 2, 'VBZ': 2, 'RB': 2, 'RBR': 2, 'VBD': 2, 'PRP': 1, 'NNS': 1, 'CC': 1, 'CD': 1, 'POS': 1, 'TO': 1}), Counter({'NN': 18, 'JJ': 7, 'VB': 4, 'RB': 2, 'CC': 2, 'PRP': 2, 'POS': 2, 'VBD': 1, 'VBP': 1, 'DT': 1, 'VBZ': 1, 'IN': 1, 'WP': 1}), Counter({'NN': 14, 'JJ': 3, 'WP': 1, 'VBZ': 1, 'VBP': 1, 'VB': 1, 'PRP': 1, 'VBD': 1, 'RB': 1, 'VBN': 1, 'IN': 1, 'DT': 1}), Counter({'NN': 21, 'JJ': 4, 'RBR': 2, 'DT': 1, 'TO': 1, 'VB': 1, '``': 1, 'CD': 1, 'JJS': 1, \"''\": 1}), Counter({'NN': 96, 'JJ': 35, 'VBP': 10, 'VB': 8, 'RB': 7, 'IN': 6, 'VBZ': 4, 'VBD': 4, 'PRP': 4, 'MD': 4, 'NNS': 4, ':': 2, 'POS': 2, 'JJS': 2, 'VBN': 2, 'WDT': 2, 'RBR': 1, 'JJR': 1, 'DT': 1, 'CC': 1, '``': 1, \"''\": 1, 'CD': 1}), Counter({'NN': 40, 'JJ': 29, 'VB': 7, 'MD': 6, 'RB': 6, 'VBP': 5, 'DT': 3, 'IN': 3, 'POS': 3, 'VBZ': 2, 'VBN': 2, 'WP': 1, 'WDT': 1, 'JJR': 1, 'CD': 1, 'NNS': 1}), Counter({'NN': 26, 'JJ': 5, 'VBP': 3, 'VBD': 3, 'IN': 3, 'VB': 2, 'DT': 2, 'CD': 1, 'NNS': 1, 'VBN': 1, 'PRP': 1, 'RB': 1, 'NNP': 1}), Counter({'NN': 14, 'FW': 1, '$': 1, 'CD': 1, 'JJ': 1, 'VBZ': 1, 'JJR': 1}), Counter({'NN': 28, 'JJ': 7, '``': 5, \"''\": 5, 'RB': 2, 'IN': 2, 'RBR': 2, 'VBP': 1, 'VB': 1, 'VBD': 1, 'VBN': 1}), Counter({'NN': 8, 'JJS': 2, 'CD': 1, 'VBN': 1, 'POS': 1, 'JJ': 1}), Counter({'NN': 27, 'JJ': 6, 'VBP': 3, 'NNS': 2, 'VBD': 2, 'VBN': 1, 'PRP': 1, 'RB': 1, 'VB': 1, 'IN': 1}), Counter({'NN': 78, 'JJ': 34, 'VBP': 6, 'RB': 6, 'FW': 4, 'IN': 4, 'VBD': 4, 'VB': 4, 'NNS': 3, 'POS': 2, 'VBN': 2, 'WP$': 2, '``': 1, \"''\": 1, 'RBR': 1, 'MD': 1}), Counter({'NN': 9, 'JJ': 6, 'VBD': 1, 'VB': 1}), Counter({'NN': 26, 'RB': 11, 'JJ': 11, 'VBP': 7, 'VB': 7, 'VBD': 2, 'MD': 2, 'WRB': 1, 'CD': 1, 'POS': 1, 'PRP': 1, 'VBN': 1, 'NNS': 1}), Counter({'NN': 14, 'JJ': 3, 'POS': 1, ':': 1, 'VBD': 1, 'RB': 1, 'VBN': 1, 'VBZ': 1, 'DT': 1, 'VB': 1, 'IN': 1}), Counter({'NN': 37, 'JJ': 12, 'VBP': 5, 'VB': 5, 'POS': 4, 'VBD': 3, '``': 3, 'DT': 3, 'IN': 2, 'RB': 2, 'CC': 2, 'NNS': 1, 'WRB': 1, \"''\": 1, 'MD': 1, 'VBZ': 1, 'VBN': 1, 'CD': 1}), Counter({'NN': 17, 'JJ': 4, 'VBD': 2, 'VBP': 2, 'RB': 2, 'VB': 1}), Counter({'NN': 111, 'JJ': 31, 'RB': 19, 'VBP': 19, 'IN': 14, 'VB': 12, 'MD': 6, 'VBD': 5, 'CC': 5, 'VBN': 4, 'PRP': 4, 'DT': 3, 'POS': 2, '``': 2, \"''\": 2, 'CD': 2, 'WRB': 1, 'VBZ': 1, 'NNS': 1, 'RBR': 1}), Counter({'NN': 32, 'JJ': 16, 'DT': 6, 'POS': 3, 'VBZ': 3, 'VBD': 3, 'RB': 3, 'VBN': 2, 'IN': 2, 'EX': 1, 'PRP': 1, 'JJR': 1, 'VBP': 1, 'VB': 1}), Counter({'NN': 16, 'JJ': 8, 'JJS': 4, 'RBS': 3, 'MD': 2, 'VB': 2, 'RB': 1, 'VBD': 1, 'NNS': 1, 'VBP': 1, 'IN': 1}), Counter({'NN': 30, 'VB': 10, 'JJ': 9, 'RB': 7, 'MD': 5, 'VBP': 4, 'DT': 2, 'IN': 2, 'POS': 2, 'TO': 1, 'NNS': 1, 'FW': 1, ':': 1, 'WRB': 1}), Counter({'NN': 10, 'JJ': 2, 'DT': 1, 'CD': 1, 'POS': 1}), Counter({'NN': 47, 'VBP': 11, 'VB': 11, 'JJ': 11, 'RB': 9, 'MD': 6, 'PRP': 4, 'IN': 4, 'NNS': 3, 'VBD': 3, 'VBZ': 3, 'JJS': 3, 'CD': 1, 'POS': 1, 'CC': 1}), Counter({'NN': 55, 'JJ': 17, 'VB': 8, 'IN': 7, 'RB': 6, 'VBP': 5, ':': 5, 'PRP': 4, 'VBD': 3, 'VBZ': 3, 'WP': 2, 'JJS': 2, 'CC': 2, 'FW': 1, 'VBN': 1, '``': 1, \"''\": 1, 'POS': 1, 'MD': 1, 'DT': 1}), Counter({'NN': 113, 'JJ': 29, 'VBP': 20, 'VB': 12, ':': 12, 'RB': 8, 'IN': 7, 'CC': 7, '``': 6, 'POS': 5, 'VBD': 5, 'DT': 4, 'VBZ': 4, 'VBN': 3, 'PRP': 3, 'NNS': 2, 'CD': 2, 'WP': 2, \"''\": 2, 'MD': 1, 'RP': 1, 'JJR': 1}), Counter({'NN': 37, 'JJ': 8, 'VBP': 5, 'RB': 4, 'DT': 3, 'VBD': 3, 'POS': 3, 'VB': 3, 'PRP': 1, 'JJR': 1, 'IN': 1, '``': 1, \"''\": 1, 'VBZ': 1, 'NNS': 1, 'MD': 1}), Counter({'NN': 7, 'VBP': 5, 'RB': 2, 'JJ': 2, 'NNS': 1, 'DT': 1}), Counter({'NN': 10, 'DT': 1, 'JJ': 1, 'IN': 1}), Counter({'NN': 62, 'JJ': 23, 'VBP': 6, 'VBD': 5, 'VB': 3, 'RB': 3, 'DT': 2, 'MD': 2, ':': 1, 'PRP': 1, 'CD': 1, 'IN': 1}), Counter({'NN': 26, 'JJ': 14, 'VBD': 4, 'RB': 4, 'VBP': 2, 'PRP': 2, 'POS': 1, 'MD': 1, 'VB': 1, 'WP$': 1, 'IN': 1, '``': 1, \"''\": 1, 'CD': 1}), Counter({'NN': 7, 'RB': 1, 'VBP': 1}), Counter({'NN': 53, 'JJ': 19, 'VBP': 8, 'RB': 4, 'IN': 3, '``': 3, \"''\": 3, 'DT': 3, 'NNS': 3, 'PRP': 2, 'VB': 2, 'VBN': 1, 'VBZ': 1, 'CD': 1, 'MD': 1}), Counter({'NN': 16, 'JJ': 8, 'VBP': 2, 'IN': 2, 'VB': 2, 'WRB': 1, 'RB': 1, 'NNS': 1, 'VBN': 1, 'DT': 1, 'FW': 1, 'MD': 1}), Counter({'NN': 145, 'JJ': 57, 'RB': 17, 'VB': 12, 'VBP': 12, 'IN': 10, 'VBD': 9, 'MD': 9, 'DT': 7, 'POS': 6, 'NNS': 6, 'VBN': 5, 'PRP': 5, 'VBZ': 5, 'CD': 2, 'JJS': 2, 'PRP$': 1, 'PDT': 1, 'RBS': 1}), Counter({'NN': 57, 'JJ': 22, 'RB': 9, 'VBZ': 6, '``': 4, \"''\": 4, 'VBN': 3, 'POS': 3, 'VBP': 3, 'VB': 3, 'VBD': 2, 'DT': 2, ':': 2, 'JJS': 1, 'IN': 1, 'NNS': 1, 'VBG': 1, 'MD': 1, 'PRP': 1, 'FW': 1, 'NNP': 1}), Counter({'NN': 103, 'JJ': 43, 'VBP': 20, 'VB': 12, 'IN': 9, 'VBD': 8, 'DT': 8, 'RB': 7, 'NNS': 6, 'PRP': 5, 'VBN': 4, 'VBZ': 4, 'CC': 4, 'CD': 3, 'MD': 2, 'JJS': 2, 'VBG': 1, '``': 1, \"''\": 1, 'WRB': 1, 'FW': 1}), Counter({'NN': 6, 'JJ': 2, 'DT': 1, 'VB': 1, 'WRB': 1}), Counter({'NN': 15, 'JJ': 9, 'IN': 3, 'RB': 2, 'DT': 2, 'PRP': 1, 'VBN': 1, 'VBD': 1, 'NNS': 1, 'VBP': 1}), Counter({'NN': 50, 'JJ': 20, 'POS': 6, 'VBZ': 4, 'VBP': 4, 'PRP': 2, 'IN': 2, 'VBD': 2, 'WDT': 1, 'RB': 1, 'FW': 1, 'NNS': 1, 'CD': 1, 'JJS': 1, 'CC': 1}), Counter({'NN': 68, 'JJ': 27, 'VBD': 13, 'VB': 6, 'PRP': 5, 'RB': 5, 'VBP': 3, 'MD': 3, 'CD': 3, 'VBZ': 2, 'RBR': 2, 'NNS': 2, 'JJS': 1, 'VBN': 1, 'WP': 1, 'IN': 1, 'DT': 1, 'RP': 1}), Counter({'NN': 23, 'VBP': 6, 'JJ': 3, 'MD': 3, 'VB': 3, 'IN': 2, 'POS': 2, 'EX': 1, 'VBD': 1, 'DT': 1, 'RB': 1}), Counter({'NN': 5, 'JJ': 4, 'VBN': 1, 'RB': 1}), Counter({'NN': 20, 'JJ': 4, 'VBP': 2, 'RB': 1, 'VB': 1, 'POS': 1, 'WP': 1, 'VBD': 1}), Counter({'NN': 3, 'VB': 2, 'VBP': 1, 'JJ': 1}), Counter({'NN': 5, 'JJ': 3, 'VBP': 2, 'RB': 1, 'VB': 1, 'POS': 1, '``': 1, \"''\": 1, 'VBD': 1}), Counter({'NN': 5, 'DT': 1, 'JJS': 1, 'CC': 1, 'VBP': 1}), Counter({'NN': 25, 'JJ': 15, 'VBP': 4, 'RB': 3, 'VBN': 2, 'VBD': 2, 'NNS': 2, 'VBZ': 2, 'DT': 2, 'PRP': 1}), Counter({'NN': 20, 'JJ': 6, 'VB': 3, 'VBZ': 3, 'NNS': 2, 'PRP': 2, 'VBP': 1, '``': 1, \"''\": 1, 'POS': 1, 'IN': 1, 'VBN': 1, 'VBD': 1, 'RB': 1}), Counter({'NN': 23, 'JJ': 8, 'VBP': 4, 'RB': 4, 'NNS': 2, 'VBD': 2, 'VB': 2, 'POS': 2, 'VBN': 1, 'RP': 1}), Counter({'NN': 8, 'JJ': 4, 'JJS': 2, 'VBZ': 1, 'IN': 1, 'VB': 1, 'JJR': 1, 'CD': 1}), Counter({'NN': 10, 'VBP': 4, 'JJ': 3, 'RB': 2, 'VB': 2, 'POS': 1}), Counter({'NN': 10, 'RB': 4, 'JJ': 2, 'RBR': 2, 'VBD': 1, 'PRP$': 1, 'IN': 1, 'VBP': 1, 'VB': 1}), Counter({'NN': 183, 'JJ': 88, 'POS': 19, 'VBP': 19, 'RB': 19, 'VB': 18, 'IN': 10, 'VBD': 7, 'MD': 7, 'NNS': 6, 'VBZ': 6, 'VBN': 4, 'CD': 3, 'JJR': 2, 'DT': 2, 'RP': 1, 'FW': 1, 'EX': 1, 'JJS': 1, 'VBG': 1, 'PRP': 1}), Counter({'NN': 99, 'JJ': 28, 'VBP': 6, 'RB': 6, 'IN': 6, 'DT': 4, 'VB': 4, 'VBD': 4, 'PRP': 4, 'VBZ': 4, 'CD': 2, ':': 2, 'MD': 1, 'VBN': 1, 'WP': 1, 'CC': 1, 'NNS': 1}), Counter({'NN': 12, 'JJ': 2, 'IN': 1, 'PRP': 1, 'VBZ': 1, 'DT': 1, 'NNS': 1, 'VBP': 1, 'RB': 1}), Counter({'NN': 25, 'JJ': 6, 'VBP': 5, 'RB': 4, 'VB': 4, 'VBD': 3, 'IN': 2, 'PRP$': 1, 'MD': 1, 'PRP': 1, 'VBZ': 1}), Counter({'NN': 12, 'JJ': 5, 'RB': 2, 'NNS': 2, 'VBP': 2, ':': 1, 'VBN': 1, 'DT': 1, 'VBD': 1, 'CC': 1}), Counter({'NN': 14, 'JJ': 6, 'CD': 2, 'JJS': 1, 'RB': 1, 'VBN': 1, 'VB': 1, 'PRP': 1, 'VBZ': 1, 'VBP': 1, 'POS': 1, 'IN': 1}), Counter({'NN': 16, 'JJ': 6, 'VBP': 3, 'VB': 3, 'RB': 2, 'VBN': 1, 'DT': 1, 'VBD': 1, 'MD': 1}), Counter({'NN': 67, 'JJ': 10, 'VBP': 7, 'VB': 7, 'IN': 6, 'DT': 5, 'CC': 2, 'POS': 2, 'RB': 2, 'VBD': 1, 'NNP': 1, 'CD': 1, 'NNS': 1, 'JJS': 1, 'WP': 1, 'VBZ': 1}), Counter({'NN': 7, 'JJ': 2, 'RB': 1, 'VBN': 1, 'CC': 1, 'IN': 1}), Counter({'NN': 12, 'JJ': 7, 'VBP': 2, 'VB': 1, 'JJR': 1, 'PRP': 1, 'RB': 1}), Counter({'NN': 3, 'DT': 1, 'VBZ': 1, 'VBP': 1, 'VB': 1, 'PRP': 1, 'RP': 1}), Counter({'NN': 204, 'JJ': 69, 'IN': 25, 'VBP': 23, 'RB': 17, 'VB': 14, 'POS': 10, 'VBD': 7, 'VBZ': 5, 'MD': 5, 'CD': 4, 'DT': 4, 'RBR': 2, 'CC': 2, 'NNS': 2, 'FW': 2, 'RP': 2, 'PRP': 1, 'NNP': 1, 'JJS': 1, 'WDT': 1, 'VBG': 1, 'JJR': 1})]\n",
            "The total verbs: 345\n",
            "The total nouns: 273\n",
            "The total adjectives: 202\n",
            "The total adverbs: 138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWrHbG8MAxMC",
        "colab_type": "code",
        "outputId": "2d4b9eae-f21e-40ce-9c5d-fee8766f3885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "# (2)Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences.\n",
        "# Download and import necessarry packages\n",
        "import spacy\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "!pip install benepar\n",
        "import benepar\n",
        "from nltk.tree import Tree \n",
        "benepar.download('benepar_en2')\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Collecting benepar\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/7b/6cd9c60e1613a5ad388b4f883fa2aeaddcd8a7ad0a8d5ed87e0d23f159d8/benepar-0.1.2.tar.gz (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from benepar) (0.29.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from benepar) (1.17.5)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.6/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.2->benepar) (1.12.0)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.1.2-cp36-cp36m-linux_x86_64.whl size=106706 sha256=998ca74c2a14eeda4612a762f1bfa17ca795e2ed5edb38552053d65ffcbac7db\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/f5/06/d88543b19a9b326007d7538298a139e994b1d2eecb003bf5af\n",
            "Successfully built benepar\n",
            "Installing collected packages: benepar\n",
            "Successfully installed benepar-0.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package benepar_en2 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTniz6JkXb8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out the constituency parsing trees\n",
        "# Preprocessing for constituency parsing and dependency parsing\n",
        "def cleaning_sentence (text):\n",
        "    step1 = remove_noise(text)\n",
        "    step2 = remove_num (step1)\n",
        "    step3 = lowercase (step2)\n",
        "    return step3\n",
        "text_4parsing = [sent.split(\".\") for sent in cleaning_sentence(raw_content)]\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy",
        "colab_type": "text"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX8JPuMM7nZ0",
        "colab_type": "text"
      },
      "source": [
        "# Answer for question 3.2\n",
        "I pulled out one sentence from my data to compare the differences between the constituency parsing tree and dependency parsing tree: \n",
        "\"i was a person that saw all the hype and claims of masterpiece as overreacting and overblown excitement for another joker based film\"\n",
        "The constituency parsing tree breaks the sentence into two main elements: Subject and Verb Phrase. Then, they are continously splited up into smaller units. In particular, Verb Phrase is broken into Verb and Noun Phrase; next, this is divided into Verb Phrase and Subordinate Clause, etc. The processes of splitting elements into smaller units are implemented from left to right until they can not be broken any more. \n",
        "In contrast, having a look the displayed dependency parsing tree, the process is pretty different. It works on each single element and its relationship with other element. What's more, it not only examines relationships of each element with the one in its right, but also to its left. For example, the verb \"was\" has two-directed relationship with subject \"I\" and \"person\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3yEB9-UyY57",
        "colab_type": "code",
        "outputId": "2ba64666-a98a-40aa-d97b-063c51ec22fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#print out the constituency parsing \n",
        "sample = [sent for sent in text_4parsing[0]]\n",
        "print (sample[0])\n",
        "parser = benepar.Parser(\"benepar_en2\")\n",
        "tree = parser.parse(sample[0])\n",
        "print(tree)\n",
        "tree.pretty_print()\n",
        "\n",
        "# Print out dependence parsing tree\n",
        "doc = nlp(sample[0])\n",
        "displacy.render(doc, style = \"dep\", jupyter=True, options={\"distance\":140})\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i was a person that saw all the hype and claims of masterpiece as overreacting and overblown excitement for another joker based film\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/benepar/base_parser.py:197: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/benepar/base_parser.py:202: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "(S\n",
            "  (NP (PRP i))\n",
            "  (VP\n",
            "    (VBD was)\n",
            "    (NP\n",
            "      (NP (DT a) (NN person))\n",
            "      (SBAR\n",
            "        (WHNP (WDT that))\n",
            "        (S\n",
            "          (VP\n",
            "            (VBD saw)\n",
            "            (NP\n",
            "              (NP (PDT all) (DT the) (NN hype) (CC and) (NNS claims))\n",
            "              (PP (IN of) (NP (NNP masterpiece))))\n",
            "            (PP\n",
            "              (IN as)\n",
            "              (NP\n",
            "                (VP (VBG overreacting))\n",
            "                (CC and)\n",
            "                (JJ overblown)\n",
            "                (NN excitement)\n",
            "                (PP\n",
            "                  (IN for)\n",
            "                  (NP\n",
            "                    (DT another)\n",
            "                    (ADJP (NN joker) (VBN based))\n",
            "                    (NN film)))))))))))\n",
            "     S                                                                                                                                                 \n",
            "  ___|____________                                                                                                                                      \n",
            " |                VP                                                                                                                                   \n",
            " |    ____________|__________                                                                                                                           \n",
            " |   |                       NP                                                                                                                        \n",
            " |   |        _______________|___________                                                                                                               \n",
            " |   |       |                          SBAR                                                                                                           \n",
            " |   |       |           ________________|___________________________________                                                                           \n",
            " |   |       |          |                                                    S                                                                         \n",
            " |   |       |          |                                                    |                                                                          \n",
            " |   |       |          |                                                    VP                                                                        \n",
            " |   |       |          |     _______________________________________________|_________________________________                                         \n",
            " |   |       |          |    |                |                                                                PP                                      \n",
            " |   |       |          |    |                |                               _________________________________|_______                                 \n",
            " |   |       |          |    |                |                              |                                         NP                              \n",
            " |   |       |          |    |                |                              |        _________________________________|_____                           \n",
            " |   |       |          |    |                NP                             |       |        |      |         |             PP                        \n",
            " |   |       |          |    |            ____|______________                |       |        |      |         |        _____|______                    \n",
            " |   |       |          |    |           |                   PP              |       |        |      |         |       |            NP                 \n",
            " |   |       |          |    |           |                ___|_______        |       |        |      |         |       |      ______|_______________    \n",
            " NP  |       NP        WHNP  |           NP              |           NP      |       VP       |      |         |       |     |          ADJP        |  \n",
            " |   |    ___|____      |    |    _______|_________      |           |       |       |        |      |         |       |     |       ____|_____     |   \n",
            "PRP VBD  DT       NN   WDT  VBD PDT  DT  NN   CC  NNS    IN         NNP      IN     VBG       CC     JJ        NN      IN    DT     NN        VBN   NN \n",
            " |   |   |        |     |    |   |   |   |    |    |     |           |       |       |        |      |         |       |     |      |          |    |   \n",
            " i  was  a      person that saw all the hype and claims  of     masterpiece  as overreacting and overblown excitement for another joker      based film\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c0d85f738b724f948e36cad9005e4afb-0\" class=\"displacy\" width=\"3270\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">i</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">person</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">that</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">saw</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">all</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1030\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1030\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1170\">hype</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1170\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1310\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1310\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">claims</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">masterpiece</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1870\">as</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1870\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2010\">overreacting</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2010\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2290\">overblown</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2290\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2430\">excitement</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2430\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2570\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2570\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2710\">another</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2710\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">joker</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2990\">based</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2990\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3130\">film</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3130\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,282.0 170.0,282.0 170.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-1\" stroke-width=\"2px\" d=\"M350,352.0 C350,282.0 450.0,282.0 450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M350,354.0 L342,342.0 358,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-2\" stroke-width=\"2px\" d=\"M210,352.0 C210,212.0 455.0,212.0 455.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M455.0,354.0 L463.0,342.0 447.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-3\" stroke-width=\"2px\" d=\"M630,352.0 C630,282.0 730.0,282.0 730.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M630,354.0 L622,342.0 638,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-4\" stroke-width=\"2px\" d=\"M490,352.0 C490,212.0 735.0,212.0 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-5\" stroke-width=\"2px\" d=\"M910,352.0 C910,212.0 1155.0,212.0 1155.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">predet</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M910,354.0 L902,342.0 918,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-6\" stroke-width=\"2px\" d=\"M1050,352.0 C1050,282.0 1150.0,282.0 1150.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1050,354.0 L1042,342.0 1058,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,142.0 1160.0,142.0 1160.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1160.0,354.0 L1168.0,342.0 1152.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-8\" stroke-width=\"2px\" d=\"M1190,352.0 C1190,282.0 1290.0,282.0 1290.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1290.0,354.0 L1298.0,342.0 1282.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-9\" stroke-width=\"2px\" d=\"M1190,352.0 C1190,212.0 1435.0,212.0 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,282.0 1570.0,282.0 1570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1570.0,354.0 L1578.0,342.0 1562.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-11\" stroke-width=\"2px\" d=\"M1610,352.0 C1610,282.0 1710.0,282.0 1710.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1710.0,354.0 L1718.0,342.0 1702.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-12\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1870.0,2.0 1870.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1870.0,354.0 L1878.0,342.0 1862.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-13\" stroke-width=\"2px\" d=\"M1890,352.0 C1890,282.0 1990.0,282.0 1990.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1990.0,354.0 L1998.0,342.0 1982.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-14\" stroke-width=\"2px\" d=\"M2030,352.0 C2030,282.0 2130.0,282.0 2130.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2130.0,354.0 L2138.0,342.0 2122.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-15\" stroke-width=\"2px\" d=\"M2310,352.0 C2310,282.0 2410.0,282.0 2410.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2310,354.0 L2302,342.0 2318,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-16\" stroke-width=\"2px\" d=\"M2030,352.0 C2030,142.0 2420.0,142.0 2420.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2420.0,354.0 L2428.0,342.0 2412.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-17\" stroke-width=\"2px\" d=\"M2030,352.0 C2030,72.0 2565.0,72.0 2565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2565.0,354.0 L2573.0,342.0 2557.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-18\" stroke-width=\"2px\" d=\"M2730,352.0 C2730,282.0 2830.0,282.0 2830.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2730,354.0 L2722,342.0 2738,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-19\" stroke-width=\"2px\" d=\"M2590,352.0 C2590,212.0 2835.0,212.0 2835.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2835.0,354.0 L2843.0,342.0 2827.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-20\" stroke-width=\"2px\" d=\"M3010,352.0 C3010,282.0 3110.0,282.0 3110.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3010,354.0 L3002,342.0 3018,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-c0d85f738b724f948e36cad9005e4afb-0-21\" stroke-width=\"2px\" d=\"M2030,352.0 C2030,2.0 3130.0,2.0 3130.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-c0d85f738b724f948e36cad9005e4afb-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3130.0,354.0 L3138.0,342.0 3122.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoKL5pFjrQyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6650e40f-d0c4-409d-f876-1f2cbb251b93"
      },
      "source": [
        "#(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity.\n",
        "hist = {}\n",
        "for sublist in text_4parsing:\n",
        "    doc = [nlp(sents) for sents in sublist]\n",
        "    for item in doc:\n",
        "      item.ents\n",
        "      for ent in item.ents:\n",
        "        print(ent.text, ent.label_)\n",
        "        hist[ent.label_]=hist.get(ent.label_,0)+1\n",
        "print(hist)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a day DATE\n",
            "joaquin PERSON\n",
            "joaquin PERSON\n",
            "2019 DATE\n",
            "one CARDINAL\n",
            "the decade DATE\n",
            "first ORDINAL\n",
            "joaquin PERSON\n",
            "arthur PERSON\n",
            "todd phillips PERSON\n",
            "yesterday DATE\n",
            "near-hour TIME\n",
            "2019 DATE\n",
            "joaquin PERSON\n",
            "oscar PERSON\n",
            "niro PERSON\n",
            "joaquin PERSON\n",
            "5 CARDINAL\n",
            "joaquin PERSON\n",
            "this year DATE\n",
            "10 CARDINAL\n",
            "robert PERSON\n",
            "october DATE\n",
            "100% PERCENT\n",
            "years ago DATE\n",
            "this tonite TIME\n",
            "jack nicholson PERSON\n",
            "todd phillips' PERSON\n",
            "arthur PERSON\n",
            "one CARDINAL\n",
            "three CARDINAL\n",
            "arthur fleck PERSON\n",
            "one CARDINAL\n",
            "the decade DATE\n",
            "dozens CARDINAL\n",
            "jack nicholson's PERSON\n",
            "90% PERCENT\n",
            "ten CARDINAL\n",
            "year DATE\n",
            "10/10 CARDINAL\n",
            "2 hour TIME\n",
            "2 hours TIME\n",
            "joaquin PERSON\n",
            "one CARDINAL\n",
            "jack PERSON\n",
            "today DATE\n",
            "first ORDINAL\n",
            "80 min QUANTITY\n",
            "8 CARDINAL\n",
            "first ORDINAL\n",
            "joaquin PERSON\n",
            "joaquin PERSON\n",
            "these 2 hours TIME\n",
            "a few hundred million dollars MONEY\n",
            "one CARDINAL\n",
            "zero CARDINAL\n",
            "8 CARDINAL\n",
            "two CARDINAL\n",
            "firstly ORDINAL\n",
            "many years DATE\n",
            "second ORDINAL\n",
            "2 hours TIME\n",
            "2 hours TIME\n",
            "the 2 hours TIME\n",
            "one CARDINAL\n",
            "half CARDINAL\n",
            "the last 5 minutes TIME\n",
            "todd phillips PERSON\n",
            "robert de niro PERSON\n",
            "like 5 minutes TIME\n",
            "about 45 minutes TIME\n",
            "about an hour TIME\n",
            "years DATE\n",
            "the hours TIME\n",
            "more than half CARDINAL\n",
            "first ORDINAL\n",
            "centuries DATE\n",
            "12y DATE\n",
            "two CARDINAL\n",
            "second ORDINAL\n",
            "9 CARDINAL\n",
            "2 hours TIME\n",
            "2019 DATE\n",
            "8 CARDINAL\n",
            "8 CARDINAL\n",
            "one CARDINAL\n",
            "52 CARDINAL\n",
            "thomas wayne PERSON\n",
            "10/10 CARDINAL\n",
            "half CARDINAL\n",
            "the past few years DATE\n",
            "2 CARDINAL\n",
            "1 CARDINAL\n",
            "10/10 CARDINAL\n",
            "todd phillips & ORG\n",
            "lawrence sher PERSON\n",
            "40 years earlier DATE\n",
            "one CARDINAL\n",
            "years DATE\n",
            "joaquin PERSON\n",
            "joaquin PERSON\n",
            "todd phillips's PERSON\n",
            "arthur PERSON\n",
            "robert de niro PERSON\n",
            "franklin PERSON\n",
            "joaquin PERSON\n",
            "5 CARDINAL\n",
            "5 CARDINAL\n",
            "first ORDINAL\n",
            "joaquin PERSON\n",
            "joaquin PERSON\n",
            "todd phillips PERSON\n",
            "1-10 CARDINAL\n",
            "10 CARDINAL\n",
            "3 CARDINAL\n",
            "this week DATE\n",
            "one CARDINAL\n",
            "second ORDINAL\n",
            "christian NORP\n",
            "robert de niro PERSON\n",
            "the year DATE\n",
            "arthur PERSON\n",
            "modern day DATE\n",
            "robert de PERSON\n",
            "thomas wayne PERSON\n",
            "one CARDINAL\n",
            "ventura GPE\n",
            "one CARDINAL\n",
            "first ORDINAL\n",
            "last night TIME\n",
            "80 DATE\n",
            "2 hours TIME\n",
            "last - this DATE\n",
            "the opening weekend DATE\n",
            "65 year old DATE\n",
            "arthur PERSON\n",
            "9 / 10mom CARDINAL\n",
            "joaquin PERSON\n",
            "de PERSON\n",
            "the year DATE\n",
            "first ORDINAL\n",
            "10 years DATE\n",
            "every minute TIME\n",
            "arthur PERSON\n",
            "2019 DATE\n",
            "this year DATE\n",
            "half an hour TIME\n",
            "bernadette PERSON\n",
            "three CARDINAL\n",
            "three CARDINAL\n",
            "the first half DATE\n",
            "one CARDINAL\n",
            "last night TIME\n",
            "7 CARDINAL\n",
            "three CARDINAL\n",
            "his 30s DATE\n",
            "his 60s DATE\n",
            "at least CARDINAL\n",
            "joaquin PERSON\n",
            "todd PERSON\n",
            "joaquin PERSON\n",
            "joaquin PERSON\n",
            "joaquin PERSON\n",
            "10 CARDINAL\n",
            "10 CARDINAL\n",
            "10 CARDINAL\n",
            "3 CARDINAL\n",
            "3 CARDINAL\n",
            "0 CARDINAL\n",
            "2019 DATE\n",
            "joaquin PERSON\n",
            "todd phillip's PERSON\n",
            "arthur PERSON\n",
            "one CARDINAL\n",
            "day DATE\n",
            "day afternoon TIME\n",
            "second ORDINAL\n",
            "2019 DATE\n",
            "lawrence sher's PERSON\n",
            "70 DATE\n",
            "first ORDINAL\n",
            "years DATE\n",
            "5 CARDINAL\n",
            "french NORP\n",
            "5 CARDINAL\n",
            "10/10 CARDINAL\n",
            "today DATE\n",
            "india GPE\n",
            "one CARDINAL\n",
            "one CARDINAL\n",
            "10 CARDINAL\n",
            "the last half an hour TIME\n",
            "joaquin PERSON\n",
            "one CARDINAL\n",
            "one CARDINAL\n",
            "one CARDINAL\n",
            "joaquin PERSON\n",
            "arthur fleck PERSON\n",
            "robert de niro's PERSON\n",
            "arthur PERSON\n",
            "arthur PERSON\n",
            "sergio PERSON\n",
            "america GPE\n",
            "robert de niro's PERSON\n",
            "the decades DATE\n",
            "indian NORP\n",
            "{'DATE': 40, 'PERSON': 60, 'CARDINAL': 61, 'ORDINAL': 13, 'TIME': 21, 'PERCENT': 2, 'QUANTITY': 1, 'MONEY': 1, 'ORG': 1, 'NORP': 3, 'GPE': 3}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}