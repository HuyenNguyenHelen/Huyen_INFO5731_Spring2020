{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_05.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/Huyen_INFO5731_Spring2020/blob/master/In_class_exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR",
        "colab_type": "text"
      },
      "source": [
        "# **The fifth in-class-exercise**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh",
        "colab_type": "text"
      },
      "source": [
        "## **1. Rule-based information extraction**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxGl5wuDQi0G",
        "colab_type": "code",
        "outputId": "60a3aa04-45b8-4370-97ae-805208356eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "import pandas as pd\n",
        "with open(\"knowledge_graph_100_titles.csv\", \"r\",  newline=\"\", encoding='utf-8') as file:\n",
        "    titles = pd.read_csv(file)\n",
        "titles\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>titles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Knowledge Graph Embedding by Translating on Hyperplanes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Learning Entity and Relation Embeddings for Knowledge Graph Completion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Knowledge Graph Embedding via Dynamic Mapping Matrix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Freebase: a collaboratively created graph database for structuring human knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Holographic Embeddings of Knowledge Graphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>How to Draw a Graph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Efficient hierarchical graph-based video segmentation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>The Graph Neural Network Model</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Group lasso with overlap and graph lasso</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0                                                                                                  titles\n",
              "0            0                                                 Knowledge Graph Embedding by Translating on Hyperplanes\n",
              "1            1                                  Learning Entity and Relation Embeddings for Knowledge Graph Completion\n",
              "2            2                                                    Knowledge Graph Embedding via Dynamic Mapping Matrix\n",
              "3            3                      Freebase: a collaboratively created graph database for structuring human knowledge\n",
              "4            4                                                              Holographic Embeddings of Knowledge Graphs\n",
              "..         ...                                                                                                     ...\n",
              "95          95                                                                                     How to Draw a Graph\n",
              "96          96                                                   Efficient hierarchical graph-based video segmentation\n",
              "97          97                                                                          The Graph Neural Network Model\n",
              "98          98  Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems\n",
              "99          99                                                                Group lasso with overlap and graph lasso\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1PtB4FnfCcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import string \n",
        "import nltk \n",
        "import spacy \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import math \n",
        "from tqdm import tqdm \n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "# load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5W_cBmqfwB8",
        "colab_type": "code",
        "outputId": "d5239c7c-cd13-4e19-9e6f-fe89a1c0ec0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "doc=nlp(str(titles[\"titles\"]))\n",
        "#token, dependency, POS tag \n",
        "# detect research methods\n",
        "for token in doc:\n",
        "  print (token.text, \"-->\",token.dep_,\"-->\", token.pos_)\n",
        "\n",
        "def find_pattern (pattern):\n",
        "  matcher = Matcher(nlp.vocab) \n",
        "  matcher.add(\"matching_1\", None, pattern) \n",
        "  matches = matcher(doc) \n",
        "  span = doc[matches[0][1]:matches[0][2]]\n",
        "  print( span.text)\n",
        "\n",
        "\n",
        "\n",
        "pattern1 = [{'POS': 'PROPN', 'OP': '*'},\n",
        "           {'POS': 'PROPN'},\n",
        "           {'lower': 'by'},\n",
        "           {'POS': 'PROPN'},\n",
        "           {'POS': 'PROPN', 'OP': '*'}\n",
        "           ]\n",
        "\n",
        "\n",
        "pattern2=[{'POS': 'PROPN', 'OP': '*'},\n",
        "           {'POS': 'PROPN'},\n",
        "           {'lower': 'via'},\n",
        "           {'POS': 'PROPN'},\n",
        "           {'POS': 'PROPN', 'OP': '*'}\n",
        "           ]\n",
        " pattern3 = [{'POS': 'PROPN', 'OP':'*'}, \n",
        "             {'POS': 'PROPN'}\n",
        "             ]\n",
        "find_pattern (pattern1)\n",
        "find_pattern (pattern2)\n",
        "\n",
        "# detect research application \n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 --> meta --> PUNCT\n",
            "                                                    -->  --> SPACE\n",
            "Knowledge --> compound --> PROPN\n",
            "Graph --> compound --> PROPN\n",
            "Embedding --> ROOT --> PROPN\n",
            "by --> prep --> ADP\n",
            "Translating --> pcomp --> PROPN\n",
            "on --> prep --> ADP\n",
            "Hyperplanes --> pobj --> PROPN\n",
            "\n",
            " -->  --> SPACE\n",
            "1 --> punct --> NUM\n",
            "                                     -->  --> SPACE\n",
            "Learning --> ROOT --> PROPN\n",
            "Entity --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Relation --> conj --> PROPN\n",
            "Embeddings --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "Knowledge --> compound --> PROPN\n",
            "Graph --> compound --> PROPN\n",
            "Completion --> pobj --> PROPN\n",
            "\n",
            " -->  --> SPACE\n",
            "2 --> dep --> NUM\n",
            "                                                       -->  --> SPACE\n",
            "Knowledge --> compound --> PROPN\n",
            "Graph --> compound --> PROPN\n",
            "Embedding --> ROOT --> PROPN\n",
            "via --> prep --> ADP\n",
            "Dynamic --> compound --> PROPN\n",
            "Mapping --> compound --> PROPN\n",
            "Matrix --> pobj --> PROPN\n",
            "\n",
            " -->  --> SPACE\n",
            "3 --> nummod --> NUM\n",
            "                         -->  --> SPACE\n",
            "Freebase --> ROOT --> PROPN\n",
            ": --> punct --> PUNCT\n",
            "a --> det --> DET\n",
            "collaboratively --> advmod --> ADV\n",
            "created --> amod --> VERB\n",
            "graph --> compound --> NOUN\n",
            "database --> appos --> NOUN\n",
            "for --> prep --> ADP\n",
            "structuring --> pcomp --> VERB\n",
            "human --> amod --> ADJ\n",
            "knowledge --> dobj --> NOUN\n",
            "\n",
            " -->  --> SPACE\n",
            "4 --> nummod --> NUM\n",
            "                                                                 -->  --> SPACE\n",
            "Holographic --> compound --> PROPN\n",
            "Embeddings --> ROOT --> PROPN\n",
            "of --> prep --> ADP\n",
            "Knowledge --> compound --> PROPN\n",
            "Graphs --> pobj --> PROPN\n",
            "\n",
            "                                                        -->  --> SPACE\n",
            "... --> punct --> PUNCT\n",
            "                                                 \n",
            " -->  --> SPACE\n",
            "95 --> nummod --> NUM\n",
            "                                                                                       -->  --> SPACE\n",
            "How --> advmod --> ADV\n",
            "to --> aux --> PART\n",
            "Draw --> ROOT --> VERB\n",
            "a --> dobj --> DET\n",
            "Graph --> pobj --> NOUN\n",
            "\n",
            " -->  --> SPACE\n",
            "96 --> nummod --> NUM\n",
            "                                                     -->  --> SPACE\n",
            "Efficient --> amod --> ADJ\n",
            "hierarchical --> amod --> ADJ\n",
            "graph --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "based --> amod --> VERB\n",
            "video --> compound --> NOUN\n",
            "segmentation --> ROOT --> NOUN\n",
            "\n",
            " -->  --> SPACE\n",
            "97 --> punct --> NUM\n",
            "                                                                            -->  --> SPACE\n",
            "The --> det --> DET\n",
            "Graph --> compound --> PROPN\n",
            "Neural --> compound --> PROPN\n",
            "Network --> compound --> PROPN\n",
            "Model --> ROOT --> PROPN\n",
            "\n",
            " -->  --> SPACE\n",
            "98 --> nummod --> NUM\n",
            "    -->  --> SPACE\n",
            "Nearly --> advmod --> ADV\n",
            "- --> punct --> PUNCT\n",
            "linear --> compound --> ADJ\n",
            "time --> compound --> NOUN\n",
            "algorithms --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "graph --> compound --> NOUN\n",
            "partitioning --> pobj --> NOUN\n",
            ", --> punct --> PUNCT\n",
            "graph --> compound --> NOUN\n",
            "sparsification --> conj --> NOUN\n",
            ", --> punct --> PUNCT\n",
            "and --> cc --> CCONJ\n",
            "solving --> conj --> VERB\n",
            "linear --> compound --> NOUN\n",
            "systems --> dobj --> NOUN\n",
            "\n",
            " -->  --> SPACE\n",
            "99 --> nummod --> NUM\n",
            "                                                                  -->  --> SPACE\n",
            "Group --> compound --> PROPN\n",
            "lasso --> dobj --> NOUN\n",
            "with --> prep --> ADP\n",
            "overlap --> nmod --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "graph --> conj --> NOUN\n",
            "lasso --> pobj --> NOUN\n",
            "\n",
            " -->  --> SPACE\n",
            "Name --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "titles --> appos --> NOUN\n",
            ", --> punct --> PUNCT\n",
            "Length --> nsubj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "100 --> appos --> NUM\n",
            ", --> punct --> PUNCT\n",
            "dtype --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "object --> dobj --> NOUN\n",
            "Knowledge Graph Embedding by Translating\n",
            "Knowledge Graph Embedding via Dynamic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4",
        "colab_type": "text"
      },
      "source": [
        "## **2. Domain-specific information extraction**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/INFO5731_Spring2020/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc7NtJrLx5tS",
        "colab_type": "code",
        "outputId": "b4f19cc8-e98d-42e6-bda1-c53fdc6dc79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# write your code here\n",
        "'''\n",
        "with open(\"cleaned_Legal.txt\", \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "print(text)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith open(\"cleaned_Legal.txt\", \"r\", newline=\"\", encoding=\"utf-8\") as f:\\n  text = f.read()\\nprint(text)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZN6spCkzGhD",
        "colab_type": "code",
        "outputId": "ccb496a7-e489-42f7-c6bd-15d4322cb02e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        }
      },
      "source": [
        "!pip install lexnlp==0.2.6\n",
        "import lexnlp.extract.en\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lexnlp==0.2.6 in /usr/local/lib/python3.6/dist-packages (0.2.6)\n",
            "Requirement already satisfied: datefinder-lexpredict==0.6.2 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (0.6.2)\n",
            "Requirement already satisfied: pandas==0.23.4 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (0.23.4)\n",
            "Requirement already satisfied: reporters-db==1.0.12.1 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (1.0.12.1)\n",
            "Requirement already satisfied: scipy==1.0.0 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (1.0.0)\n",
            "Requirement already satisfied: Unidecode==0.4.21 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (0.4.21)\n",
            "Requirement already satisfied: scikit-learn==0.19.1 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (0.19.1)\n",
            "Requirement already satisfied: pycountry==18.5.26 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (18.5.26)\n",
            "Requirement already satisfied: us==1.0.0 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (1.0.0)\n",
            "Requirement already satisfied: dateparser==0.7.0 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (0.7.0)\n",
            "Requirement already satisfied: typing==3.6.2 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (3.6.2)\n",
            "Requirement already satisfied: gensim==3.4.0 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (3.4.0)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (2.21.0)\n",
            "Requirement already satisfied: num2words==0.5.5 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (0.5.5)\n",
            "Requirement already satisfied: nltk==3.2.4 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (3.2.4)\n",
            "Requirement already satisfied: regex==2017.9.23 in /usr/local/lib/python3.6/dist-packages (from lexnlp==0.2.6) (2017.9.23)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datefinder-lexpredict==0.6.2->lexnlp==0.2.6) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from datefinder-lexpredict==0.6.2->lexnlp==0.2.6) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.23.4->lexnlp==0.2.6) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from reporters-db==1.0.12.1->lexnlp==0.2.6) (1.12.0)\n",
            "Requirement already satisfied: jellyfish==0.5.6 in /usr/local/lib/python3.6/dist-packages (from us==1.0.0->lexnlp==0.2.6) (0.5.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from dateparser==0.7.0->lexnlp==0.2.6) (1.5.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.4.0->lexnlp==0.2.6) (1.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->lexnlp==0.2.6) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->lexnlp==0.2.6) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->lexnlp==0.2.6) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->lexnlp==0.2.6) (1.24.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.4.0->lexnlp==0.2.6) (1.11.15)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim==3.4.0->lexnlp==0.2.6) (2.49.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==3.4.0->lexnlp==0.2.6) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==3.4.0->lexnlp==0.2.6) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim==3.4.0->lexnlp==0.2.6) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim==3.4.0->lexnlp==0.2.6) (0.15.2)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXA2XRK00biu",
        "colab_type": "code",
        "outputId": "48888e9a-726a-4171-b216-cb43302e4898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "try:\n",
        "  print(list(lexnlp.extract.en.acts.get_acts(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.amounts.get_amounts(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.citations.get_citations(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.companies.get_companies(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.conditions.get_conditions(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.constraints.get_constraints(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.copyright.get_copyright(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.courts.get_courts(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.CUSIP.get_CUSIP(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.dates.get_dates(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.definitions.get_definitions(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.durations.get_durations(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.geoentities.get_geoentities(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.money.get_money(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.percents.get_percents(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.pii.get_pii(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.ratios.get_ratios(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.regulations.get_regulations(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.trademarks.get_trademarks(text)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.urls.get_urls(text)))\n",
        "except:\n",
        "  print(None)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8w9sc85PmC",
        "colab_type": "code",
        "outputId": "a80410b9-3b0e-452d-de46-f31b571d805a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# write your code here\n",
        "with open(\"Legal.txt\", \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "  text1 = f.read()\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.acts.get_act_list(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.amounts.get_amounts(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.citations.get_citations(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.entities.nltk_re.get_entities.nltk_re.get_companies(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.conditions.get_conditions(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.constraints.get_constraints(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.copyright.get_copyright(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.courts.get_courts(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.CUSIP.get_CUSIP(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.dates.get_dates(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.definitions.get_definitions(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.durations.get_durations(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.geoentities.get_geoentities(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.money.get_money(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.percents.get_percents(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.pii.get_pii(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.ratios.get_ratios(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.regulations.get_regulations(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.trademarks.get_trademarks(text1)))\n",
        "except:\n",
        "  print(None)\n",
        "try:\n",
        "  print(list(lexnlp.extract.en.urls.get_urls(text1)))\n",
        "except:\n",
        "  print(None)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLSQu8Vo7xBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1=\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}