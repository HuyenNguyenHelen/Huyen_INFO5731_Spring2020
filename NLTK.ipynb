{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/Huyen_INFO5731_Spring2020/blob/master/NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0W-Z1k4sptz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92e779e8-d988-445b-b04b-838e1e1eaa45"
      },
      "source": [
        "import nltk\n",
        "nltk.download()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> 1\n",
            "Command '1' unrecognized\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> 1)\n",
            "Command '1)' unrecognized\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> l)\n",
            "Command 'l)' unrecognized\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> book\n",
            "    Downloading collection 'book'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | \n",
            "     Done downloading collection book\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "197qqJLIutoz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "e4917736-469a-4fe4-a6d6-348715a8b2a7"
      },
      "source": [
        "from nltk.book import *\n",
        "text5.concordance(\"friend\")\n",
        "text5.concordance(\"perfect\")\n",
        "text3.concordance(\"lived\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Displaying 8 of 8 matches:\n",
            "ur nose .. But you ca n't pick your friend s nose . JOIN . ACTION sticks his f\n",
            "e U85 Your name looks male to me My friend had a horse name U86 lol donno why \n",
            "t's sucks JOIN I caught Mono from a friend s drink lol . ACTION . Liam 's . 13\n",
            "ut not really besides U45 who is my friend PART hes cool too Anyone wanna Cybe\n",
            " broke come on now guys LOL you can friend him , lex , and lois ! buy U54 a pu\n",
            "luids Elle went out with her fruity friend to a bar PART JOIN U50 PART how you\n",
            "am girls pm me 22 f arizona here my friend studied in little rock for a year h\n",
            "in Catterick do you ? I have a good friend that lives there . im gonna be ther\n",
            "Displaying 2 of 2 matches:\n",
            "er how to cook .. turn her into the perfect lil housewife for ya . any females \n",
            "Hello Richard . your cat walks in a perfect line , im impressed ! Sup Joe . JOI\n",
            "Displaying 25 of 38 matches:\n",
            "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
            "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
            "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
            "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
            "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
            " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
            "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
            "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
            "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
            "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
            "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
            "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
            " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
            " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
            " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
            "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
            "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
            "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
            "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
            "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
            "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
            "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
            "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
            " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
            "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n",
            "true contemptible christian abundant few part mean careful puzzled\n",
            "mystifying passing curious loving wise doleful gamesome singular\n",
            "delightfully perilous fearless\n",
            "very so exceedingly heartily a as good great extremely remarkably\n",
            "sweet vast amazingly\n",
            "No matches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUfbMTr6wvsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6e83ff3f-8df4-4ba9-bbe1-2146bf572ddc"
      },
      "source": [
        "text1.similar(\"monstrous\")\n",
        "text2.similar(\"monstrous\")\n",
        "text3.similar(\"monstrous\")\n",
        "text1.similar(\"monstrous\")\n",
        "text2.similar(\"monstrous\")\n",
        "text4.similar(\"monstrous\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true contemptible christian abundant few part mean careful puzzled\n",
            "mystifying passing curious loving wise doleful gamesome singular\n",
            "delightfully perilous fearless\n",
            "very so exceedingly heartily a as good great extremely remarkably\n",
            "sweet vast amazingly\n",
            "No matches\n",
            "true contemptible christian abundant few part mean careful puzzled\n",
            "mystifying passing curious loving wise doleful gamesome singular\n",
            "delightfully perilous fearless\n",
            "very so exceedingly heartily a as good great extremely remarkably\n",
            "sweet vast amazingly\n",
            "No matches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcaP3pTKxLfY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3b6d5624-2cb2-4acd-9141-33a1626a9605"
      },
      "source": [
        "text2.common_contexts([\"monstrous\", \"very\"])\n",
        "text1.common_contexts([\"monstrous\", \"very\"])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_pretty am_glad a_lucky is_pretty be_glad\n",
            "No common contexts were found\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}